<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IOPsychist</title>
    <link>https://iopsychist.netlify.app/</link>
      <atom:link href="https://iopsychist.netlify.app/index.xml" rel="self" type="application/rss+xml" />
    <description>IOPsychist</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2024</copyright><lastBuildDate>Sat, 01 Jun 2030 13:00:00 +0000</lastBuildDate>
    <image>
      <url>https://iopsychist.netlify.app/media/sharing.png</url>
      <title>IOPsychist</title>
      <link>https://iopsychist.netlify.app/</link>
    </image>
    
    <item>
      <title>Python basics</title>
      <link>https://iopsychist.netlify.app/courses/example/python/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/courses/example/python/</guid>
      <description>&lt;p&gt;Build a foundation in Python.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/rfscVS0vtbw&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the difference between lists and tuples?&lt;/summary&gt;
  &lt;p&gt;&lt;p&gt;Lists&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lists are mutable - they can be changed&lt;/li&gt;
&lt;li&gt;Slower than tuples&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_list = [1, 2.0, &#39;Hello world&#39;]&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tuples&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tuples are immutable - they can&amp;rsquo;t be changed&lt;/li&gt;
&lt;li&gt;Tuples are faster than lists&lt;/li&gt;
&lt;li&gt;Syntax: &lt;code&gt;a_tuple = (1, 2.0, &#39;Hello world&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Is Python case-sensitive?&lt;/summary&gt;
  &lt;p&gt;Yes&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Visualization</title>
      <link>https://iopsychist.netlify.app/courses/example/visualization/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/courses/example/visualization/</guid>
      <description>&lt;p&gt;Learn how to visualize data with Plotly.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/hSPmj7mK6ng&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;When is a heatmap useful?&lt;/summary&gt;
  &lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit.&lt;/p&gt;
&lt;/details&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-3&#34;&gt;
  &lt;summary&gt;Write Plotly code to render a bar chart&lt;/summary&gt;
  &lt;p&gt;&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import plotly.express as px
data_canada = px.data.gapminder().query(&amp;quot;country == &#39;Canada&#39;&amp;quot;)
fig = px.bar(data_canada, x=&#39;year&#39;, y=&#39;pop&#39;)
fig.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Statistics</title>
      <link>https://iopsychist.netlify.app/courses/example/stats/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/courses/example/stats/</guid>
      <description>&lt;p&gt;Introduction to statistics for data science.&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-clock  pr-1 fa-fw&#34;&gt;&lt;/i&gt; 1-2 hours per week, for 8 weeks&lt;/p&gt;
&lt;h2 id=&#34;learn&#34;&gt;Learn&lt;/h2&gt;
&lt;p&gt;The general form of the &lt;strong&gt;normal&lt;/strong&gt; probability density function is:&lt;/p&gt;
&lt;p&gt;$$
f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}
$$&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    The parameter $\mu$ is the mean or expectation of the distribution.
$\sigma$ is its standard deviation.
The variance of the distribution is $\sigma^{2}$.
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&#34;quiz&#34;&gt;Quiz&lt;/h2&gt;
&lt;details class=&#34;spoiler &#34;  id=&#34;spoiler-2&#34;&gt;
  &lt;summary&gt;What is the parameter $\mu$?&lt;/summary&gt;
  &lt;p&gt;The parameter $\mu$ is the mean or expectation of the distribution.&lt;/p&gt;
&lt;/details&gt;</description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>https://iopsychist.netlify.app/talk/example-talk/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/talk/example-talk/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;page elements&lt;/a&gt; such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SIOP ML Competition 2024 - LLMs</title>
      <link>https://iopsychist.netlify.app/post/siop-ml-competition-2024/</link>
      <pubDate>Thu, 11 Apr 2024 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/siop-ml-competition-2024/</guid>
      <description>&lt;h1 id=&#34;harnessing-the-power-of-generative-ai-in-io-psychology-insights-from-the-siop-2024-machine-learning-competition&#34;&gt;Harnessing the Power of Generative AI in I/O Psychology: Insights from the SIOP 2024 Machine Learning Competition&lt;/h1&gt;
&lt;p&gt;I recently had the exhilarating opportunity to participate in the SIOP 2024 Machine Learning Competition, a pioneering event sponsored by HackerRank, DDI, and the Department of Psychology at Virginia Tech. This competition was a playground for showcasing the synergy between Large Language Models (LLMs) and Industrial/Organizational (I/O) Psychology, aiming to explore the potentials and boundaries of AI in our field.&lt;/p&gt;
&lt;h2 id=&#34;the-challenge-and-my-journey&#34;&gt;The Challenge and My Journey&lt;/h2&gt;
&lt;p&gt;The competition posed four intriguing challenges, each designed to reflect common tasks in I/O Psychology:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Predicting Empathy in Workplace Responses&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generating Interview Responses&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rating Item Clarity for Personality Tests&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Identifying Fairness Perceptions in Organizational Policies&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Using a quantized Mixtral model (a mixture of experts), I ventured into these tasks with a mix of curiosity and technical acumen. My approach involved crafting Python scripts in a Google Colab notebook, meticulously tuning the model to resonate with the intricacies of I/O psychology-related queries.&lt;/p&gt;
&lt;h2 id=&#34;surpassing-expectations-with-llms&#34;&gt;Surpassing Expectations with LLMs&lt;/h2&gt;
&lt;p&gt;The journey was not just about solving problems but also about discovering the remarkable capabilities of LLMs in understanding and predicting human behavior and organizational phenomena. To my delight, the accuracy of my solutions surpassed expectations, underscoring the robustness and adaptability of LLMs in handling nuanced psychological data.&lt;/p&gt;
&lt;h2 id=&#34;why-people-analytics-and-io-psychology-should-embrace-generative-ai&#34;&gt;Why People Analytics and I/O Psychology Should Embrace Generative AI&lt;/h2&gt;
&lt;p&gt;My experiences during the competition solidified my belief that People Analytics professionals and I/O Psychologists are uniquely positioned to leverage Generative AI. Our foundational skills in analyzing human behavior and organizational dynamics align seamlessly with the capabilities of LLMs, allowing us to extract meaningful insights and foster innovation in our practices.&lt;/p&gt;
&lt;h2 id=&#34;sharing-the-knowledge&#34;&gt;Sharing the Knowledge&lt;/h2&gt;
&lt;p&gt;In the spirit of collaboration and knowledge-sharing, I have made my code available on GitHub. This repository not only contains the scripts used in the competition but also serves as a resource for those interested in integrating Generative AI into their I/O Psychology workflows.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/YourGitHubProfile/SIOP2024_ML_Competition_Code&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Check out my GitHub repository for the competition code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In conclusion, the SIOP 2024 Machine Learning Competition was not just a contest but a learning journey that highlighted the symbiotic relationship between I/O Psychology and Generative AI. As we move forward, embracing these advanced technologies will undoubtedly lead to more innovative, efficient, and effective outcomes in our field.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I presented at The 11th Annual Conference on Human Capital Innovation in Technology &amp; Analytics (slides attached)</title>
      <link>https://iopsychist.netlify.app/post/recap-the-11th-annual-conference-on-human-capital-innovation-in-technology-analytics/</link>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/recap-the-11th-annual-conference-on-human-capital-innovation-in-technology-analytics/</guid>
      <description>
&lt;script src=&#34;https://iopsychist.netlify.app/post/recap-the-11th-annual-conference-on-human-capital-innovation-in-technology-analytics/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;the-11th-annual-conference-on-human-capital-innovation-in-technology-analytics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The 11th Annual Conference on Human Capital Innovation in Technology &amp;amp; Analytics&lt;/h2&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;In April, I had my first opportunity to present at an academic conference - the 11th Annual Conference on &lt;a href=&#34;http://www.nyu.engineering/events/2022/04/26/11th-annual-conference-human-capital-innovation-technology-analytics&#34;&gt;Human Capital Innovation in Technology and Analytics&lt;/a&gt; at NYU. This yearâs topic was âThe Great Resignation: How Analytics Can Helpâ. I spoke about some of the work Iâve been involved in with Frank Mo and the Human Capital Analytics Lab to forecast job demand in the Knowledge Worker and Service Worker industries. I learned quite a bit through the process of preparing for, presenting, and discussing our work. It was very cool to hear what the other presenters were working on in their companies and research institutes as well. Also among the speakers were team members from the Conference Board, Accenture, Microsoft, and Johnson &amp;amp; Johnson - quite a lineup to follow!&lt;/p&gt;
&lt;p&gt;In our research, we worked with data from &lt;a href=&#34;http://candogram.com&#34;&gt;Candogram&lt;/a&gt; - an awesome company that provides job market education to students and, in doing so, processes 2 million job ads per day from 10,000 US employers - and from the BLS &lt;a href=&#34;http://https://www.bls.gov/jlt/&#34;&gt;Job Openings and Labor Turnover survey (JOLTS)&lt;/a&gt;. Our central research question looked at the spike in voluntary quits during the Great Resignation as a precipitating event for changes in labor market demand. To uncover insight into this, we tested two advanced time series forecasting methods - Facebookâs &lt;a href=&#34;https://facebook.github.io/prophet/&#34;&gt;Prophet&lt;/a&gt; model and LinkedInâs &lt;a href=&#34;https://engineering.linkedin.com/blog/2021/greykite--a-flexible--intuitive--and-fast-forecasting-library&#34;&gt;Silverkite&lt;/a&gt; model. It turns out there is a relationship between job quits and job demand, but it depends on which industry youâre looking at!&lt;/p&gt;
&lt;p&gt;We are currently working on a white paper which we hope to release in the next few weeks but you can get a sneak peak into what we found from the slide deck from our presentation. This is just the start and there are many future directions we are considering. In the meantime, weâd love to hear your thoughts and feedback! Stay tuned for further updates coming soon.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_1.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_2.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_3.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_4.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_5.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_6.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_7.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_8.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_9.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_10.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_11.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_12.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_13.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_14.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_15.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_16.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_17.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_18.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_19.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_20.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/hcita_2022_21.jpeg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: July 11, 2022&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Survey Response Distributions</title>
      <link>https://iopsychist.netlify.app/post/visualizing-survey-response-distributions/</link>
      <pubDate>Tue, 05 Jul 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/visualizing-survey-response-distributions/</guid>
      <description>
&lt;script src=&#34;https://iopsychist.netlify.app/post/visualizing-survey-response-distributions/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I recently supported an organization with running their annual engagement survey. The survey was divided into six sections, focusing on themes such as âMy Jobâ, âTrust in Leadershipâ, and âCompensation and Benefitsâ. A section of particular interest to the head of HR was the âMy Managerâ section. In this section, employees responded to 13 questions on a 5 point scale:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My manager communicates clear goals for our team.&lt;/li&gt;
&lt;li&gt;My manager ensures that I am well-informed about issues that affect my work.&lt;/li&gt;
&lt;li&gt;My manager supports my professional growth and development.&lt;/li&gt;
&lt;li&gt;My manager has had a meaningful discussion with me about my career development in the past six months.&lt;/li&gt;
&lt;li&gt;My manager gives actionable feedback on a regular basis.&lt;/li&gt;
&lt;li&gt;My manager provides the autonomy I need to do my job.&lt;/li&gt;
&lt;li&gt;The actions of my manager show they value the perspective I bring to the team, even if it is different from their own.&lt;/li&gt;
&lt;li&gt;My manager does a good job in focusing our team on the most important work&lt;/li&gt;
&lt;li&gt;My manager does an effective job at helping me and my teammates adapt to changes affecting our department.&lt;/li&gt;
&lt;li&gt;My manager effectively collaborates across departments.&lt;/li&gt;
&lt;li&gt;I would consider my manager to be an effective decision maker.&lt;/li&gt;
&lt;li&gt;My manager holds the team accountable for demonstrating [Company]âs values while driving results.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Response options were âStrongly Disagreeâ, âDisagreeâ, âNeutralâ, âAgreeâ, and âStrongly Agreeâ&lt;/p&gt;
&lt;p&gt;With survey data, especially in industry, it is often helpful to understand the response distributions to each questions. Luckily, the R package ggridges can help us do so quickly and easily.&lt;/p&gt;
&lt;p&gt;Since the actual data is confidential, I will simulate a response pattern and show how
item distributions can be visualized using ggplot and ggridges.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# import required packages
library(readxl)
library(dplyr)
library(stringr)
library(tidyr)
library(ggplot2)
library(ggridges)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;simulate-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulate Data&lt;/h2&gt;
&lt;p&gt;To start, letâs create a dataset of 100 âtrueâ levels of the underlying trait we are interested in measuring.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1359)
N = 100            # let&amp;#39;s say we had 100 respondents

# each respondent has a &amp;#39;true&amp;#39; score on the latent variable we are measuring
# let&amp;#39;s model that here, assuming a normal distribution
latent = rnorm(N, mean = 0, sd = 1)

# each measurement will have a slight error on top of the true score
# define that error for each of the 13 items we will generate
sds &amp;lt;- runif(n=13, min=0, max=1.5)


# initialize our items and vals list
items = c()
vals &amp;lt;- list()

# create item responses for each 13 items
for (i in seq(length(sds))) {
  items &amp;lt;- append(items, paste0(&amp;#39;item&amp;#39;, i))
  scores &amp;lt;- latent + rnorm(N, mean=0, sd=sds[i])
  vals[i] &amp;lt;- list(scores)
}

# name the list and cast to dataframe
names(vals) &amp;lt;- items
dat &amp;lt;- as.data.frame(vals)  # we now have a dataframe of each employee&amp;#39;s score on each item&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have the data of each employeeâs true score on the measure.&lt;/p&gt;
&lt;p&gt;While each employee has a âtrueâ level on the latent variable, in reality they also have a âresponseâ level they would indicate based on the question design. For example, Sam is experiencing moderate-high levels of burnout - their true burnout level is 7 out of 10. Sam reads a survey question aimed at identifying burnout: âI feel burnout out from the demands of my jobâ with 5 response options ranging from Strongly Disagree to Agree. Sam selects âAgreeâ. Another employee, Jordan, is not as burned out - their true level is a 5 out of 10. Jordan reads the same question and thinks, âwell, I do &lt;em&gt;feel&lt;/em&gt; burnout from the demands of my job. Itâs mostly manageable but I still agree with the statement, so I will indicate âAgreeââ. Both Sam and Jordan responded to the item with the same response, even though their âtrueâ score, the level of burnout they are experiencing, is different.&lt;/p&gt;
&lt;p&gt;We can model this interaction by defining interval buckets to categorize how an employee would
respond based on their true score. For now, we will assume all items are positively scored (i.e the higher the response score, the higher the underlying True score). In most companies that use survey questions measured on the scale described previously, the majority of employees will select âAgreeâ or âStrongly Agreeâ. Those that do not will tend to select the neutral option, and the very few employees remaining will indicate some level of disagreement. Therefore, we will define our response intervals as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if an employeeâs true score is very very low (2.5 or more standard deviations below the mean),they will respond with âStrongly Disagreeâ.&lt;/li&gt;
&lt;li&gt;For those employees 2.5-2 deviations below the mean, they will select âDisagreeâ&lt;/li&gt;
&lt;li&gt;Employees who are 2 to -0.5 deviations below the mean indicate âNeutralâ&lt;/li&gt;
&lt;li&gt;Employees 0.5 below the mean to 1 deviation above will select âAgreeâ.&lt;/li&gt;
&lt;li&gt;The rest will select âStrongly Agreeâ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can define these interval breakpoints in a list &lt;code&gt;c(-Inf, -2.5, -2, -.5, 1, Inf)&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;##### generate latent responses to items
# apply findInterval function to convert latent scores to ordered categories
dat &amp;lt;- dat |&amp;gt;
  mutate(across(starts_with(&amp;#39;item&amp;#39;), ~ findInterval(.x, vec = c(-Inf, -2.5, -2, -.5, 1, Inf))))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plot-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot the data&lt;/h2&gt;
&lt;p&gt;Finally, we can plot our item response distributions to better understand our results. The ggridges package extends ggplot and helps us create a stacked graph of the density of responses to each item. We can use this to quickly visualize and compare each item.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# create ridgeline density plot (uses ggridges packages)
dat |&amp;gt;
  # we pivot longer so we can use item# as Y and Fill value
  pivot_longer(where(is.numeric), names_to = &amp;#39;Question&amp;#39;, values_to = &amp;#39;Score&amp;#39;) |&amp;gt;
  ggplot(aes(x=Score, y = Question, fill = Question)) +
  # call the geom_density_ridge() function
  geom_density_ridges() +
  theme_ridges() +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  # use the limit function to properly order our items
  # since they are alphanumeric, the default sort would 
  # be item1, item10, item11, item12, item13, item2, item3...
  scale_y_discrete(limits = items)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 0.323&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://iopsychist.netlify.app/post/visualizing-survey-response-distributions/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interpeting-the-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Interpeting the results&lt;/h2&gt;
&lt;p&gt;From the ridge plot, we can quickly get a sense of how the survey items functioned. For the most part, responses followed the pattern we would expect. However, there are a few items where we seem to observe higher levels of disagreement than other items (item 11, for example). This could be a hotspot we need to investigate further. Additionally, a few items appear to be more positively skewed (item 7, for instance) - perhaps we should revise these items for the next iteration to allow us to gain deeper insights. If we were to run further analyses using engagement survey responses, such as regression, it may be useful to rescale responses to better fit the assumptions as well.&lt;/p&gt;
&lt;p&gt;The distributions plotted above are fairly uniform due to how we simulated the data but even still there are some differences. Often times there will be more evident differences in means, distributions, and clusters of items that help drive further insight. Just a few extra lines of code will help you add value for your stakeholders.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: July 5, 2022&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tutorial: Pay Equity Analysis [Part 2]</title>
      <link>https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-2/</link>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-2/</guid>
      <description>
&lt;script src=&#34;https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-2/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;coming-soon&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Coming Soon&lt;/h1&gt;
&lt;/div&gt;
&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;This is part 2 of the Pay Equity Analysis. In part 1, we gathered the dataset we will be using which contains pay information on City of Philadelphia employees. In part 2 we will conduct the actual pay equity analysis. The goal is to present an example of how a pay equity analysis may be conducted that can be used in your organization. The tutorial consists of two main phases:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Data Collection and Cleaning&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;This step uses Python for scraping the data from the web and collecting it into a workable file for analysis. We use a basic method to impute gender identification to give us a more real world example (note: this also limits the accuracy of our analysis. These results should not be interpreted to be an actual representation of pay equity among City of Philadelphia employees). Likely you will have direct access to the necessary data through your organization and this step will be unnecessary. Feel free to skip to the next section if so. However, if you are looking for a working data set to practice on your own, this section may be helpful.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Pay Equity Analysis&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;This is likely where you will start within your organization. I walk through two methods for analyzing pay data â Regression as well as Classification and Regression Tree (CART) modeling. The analysis has been conducted using R.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Setup

#load packages
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ââ Attaching packages âââââââââââââââââââââââââââââââââââââââ tidyverse 1.3.1 ââ&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## â ggplot2 3.3.5     â purrr   0.3.4
## â tibble  3.1.6     â dplyr   1.0.8
## â tidyr   1.1.3     â stringr 1.4.0
## â readr   1.4.0     â forcats 0.5.1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;dplyr&amp;#39; was built under R version 4.1.2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## ââ Conflicts ââââââââââââââââââââââââââââââââââââââââââ tidyverse_conflicts() ââ
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# read in the data
mydata &amp;lt;- read_csv(&amp;#39;MVR_preprocessed_data.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Missing column names filled in: &amp;#39;X1&amp;#39; [1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## ââ Column specification ââââââââââââââââââââââââââââââââââââââââââââââââââââââââ
## cols(
##   X1 = col_double(),
##   last_name = col_character(),
##   first_name = col_character(),
##   title = col_character(),
##   job_code = col_character(),
##   department_name = col_character(),
##   department_number = col_double(),
##   base_salary = col_double(),
##   likely_male = col_double(),
##   likely_female = col_double(),
##   jobClassCode = col_character(),
##   jobClassTitle = col_character(),
##   payRange = col_character(),
##   jobClassSalaryMin = col_double(),
##   jobClassSalaryMax = col_double(),
##   unionCode = col_character(),
##   flsaCode = col_character(),
##   effectiveDate = col_date(format = &amp;quot;&amp;quot;),
##   family = col_double()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: January 18, 2022&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Impact of Sign-on and Retention Bonuses on Extrinsic Motivation</title>
      <link>https://iopsychist.netlify.app/post/the-impact-of-sign-on-and-retention-bonuses-on-extrinsic-motivation/</link>
      <pubDate>Wed, 02 Feb 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/the-impact-of-sign-on-and-retention-bonuses-on-extrinsic-motivation/</guid>
      <description>&lt;br&gt;  
&lt;p&gt;&lt;font size=&#34;5&#34;&gt;A recent&lt;/font&gt; SHRM survey found that during the tight labor market spurred by the Covid-19 pandemic, companies &lt;a href=&#34;https://www.shrm.org/resourcesandtools/hr-topics/compensation/pages/employers-rely-on-incidental-bonuses-amid-tight-labor-market.aspx&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;âstepped up their use of sign-on, referral, spot and retention bonuses to attract and keep employees.â&lt;/a&gt; One company found that job ads &lt;a href=&#34;https://www.forbes.com/sites/jackkelly/2021/09/08/companies-are-paying-100000-sign-on-bonuses-to-attract-workers/?sh=2488ad2d3b9f&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;offering a sign-on bonus have increased across all sectors by a whopping 454%, from 10,312 positions in August 2020 to 57,123 in August 2021.â&lt;/a&gt; These types of rewards, also called &lt;strong&gt;incidental rewards&lt;/strong&gt;, have been used to effectively increase employee earnings during the pandemic.&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;style&gt;
div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
&lt;/style&gt;
&lt;div class = &#34;blue&#34;&gt;
SHRM survey fast facts:  
&lt;ul&gt;
&lt;li&gt;52 percent of respondents increased the number of sign-on bonuses awarded in the past 12 months.&lt;/li&gt;
&lt;li&gt;49 percent have increased the number of retention bonuses awarded&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p&gt;&lt;font size=&#34;5&#34;&gt;Prior&lt;/font&gt; to the pandemic, real wage growth in the US was &lt;a href=&#34;https://www.pewresearch.org/fact-tank/2018/08/07/for-most-us-workers-real-wages-have-barely-budged-for-decades/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;relatively stagnant&lt;/a&gt; despite hot job markets and a substantial increase in productivity. This discrepancy disproportionately affected lower income brackets, contributing to further inequality in earnings. These low-skilled jobs often form a company&amp;rsquo;s front-line workforce - a.k.a. those with the highest risk of infection during a pandemic. Covid-19 forced a lot of companies to recognize the importance of these employees to their operating models. It is quicker and easier to provide one-time bonuses or extra-salary compensation than adjust the entire compensation framework for a company. As a policy, it is also easier to unwind post pandemic. Together with increased competition for labor, this was a quick way for companies to respond as the tight market dynamics arose.&lt;/p&gt;
&lt;p&gt;&lt;font size=&#34;5&#34;&gt;However,&lt;/font&gt; rewards based on participation or engagement (as opposed to performance-based rewards) are perhaps the most detrimental type of reward to internal motivation. Why is this important? While the difference between a wage increase and a bonus may be important to employers, the total earnings are more salient to employees than the method by which they were received. Given that we&amp;rsquo;ve now been operating in &amp;lsquo;pandemic-mode&amp;rsquo; for over 20 months, employees may come to expect the total package they are receiving. Furthermore, these bonuses provide extrinsic motivation which works to shift workers&#39; motivation away from any intrinsic sources they have conceived of previously. &lt;strong&gt;All else being equal, it is harder to shift from extrinsic to intrinsic motivation&lt;/strong&gt;. When these external rewards dry up, companies will face challenges in motivating their employees.&lt;/p&gt;
&lt;p&gt;&lt;font size=&#34;5&#34;&gt;From&lt;/font&gt; an I/O perspective, employee motivation should be an important consideration when deciding how to maneuver. This awareness may not make it into the room where compensation and bonus decisions are being made. Viewed purely from a financial lens it may seem attractive to roll back variable pay. However, rolling back expected earnings may hurt employee motivation, thereby decreasing productivity. This loss in output per employee may incur more overall costs to the company in the form of presenteeism, loss of organizational citizenship behavior, and increased hiring costs. &lt;mark&gt;Whether these externalities cost the company more than the compensation savings is a question each employer will have to answer for themselves.&lt;/mark&gt; Regardless, unwinding pandemic-era cash incentives will be a line that employers must navigate as they carve a path forward, and is not as simple as simply returning to the way things were pre-Covid.&lt;/p&gt;
&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: February 2, 2022&lt;/font&gt;</description>
    </item>
    
    <item>
      <title>Tutorial: Pay Equity Analysis [Part 1]</title>
      <link>https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-1/</link>
      <pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-1/</guid>
      <description>
&lt;script src=&#34;https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-1/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;overview&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Overview&lt;/h1&gt;
&lt;p&gt;In this tutorial, we will conduct a pay equity analysis on publicly available pay information for the City of Philadelphia. The goal is to present an example of how a pay equity analysis may be conducted that can be used in your organization. The tutorial consists of two main phases:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Data Collection and Cleaning&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;This step uses Python for scraping the data from the web and collecting it into a workable file for analysis. We use a basic method to impute gender identification to give us a more real world example (note: this also limits the accuracy of our analysis. These results should not be interpreted to be an actual representation of pay equity among City of Philadelphia employees). Likely you will have direct access to the necessary data through your organization and this step will be unnecessary. Feel free to skip to the next section if so. However, if you are looking for a working data set to practice on your own, this section may be helpful.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Pay Equity Analysis&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;This is likely where you will start within your organization. I walk through two methods for analyzing pay data â Regression as well as Classification and Regression Tree (CART) modeling. The analysis has been conducted using R.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;part-1---data-collecetion-and-cleaning&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Part 1 - Data Collecetion and Cleaning&lt;/h1&gt;
&lt;div id=&#34;employee-salary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Employee Salary&lt;/h2&gt;
&lt;p&gt;The City of Philadelphia participates in an &lt;a href=&#34;opendataphilly.org&#34;&gt;Open Data program&lt;/a&gt; where they publish many different data sets related to the Philadelphia region, including information on pay for public employees. Using this resource, we can pull in the bulk of the data necessary to conduct a pay equity analysis. To begin with, letâs import the necessary Python packages we will need. On top of the typical data science tools (pandas, numpy, seaborn, etc), we will be using &lt;code&gt;requests&lt;/code&gt; for our API calls, &lt;code&gt;json&lt;/code&gt; for parsing the data we get back, and &lt;code&gt;BeautifulSoup&lt;/code&gt; for web scraping. There are a few auxiliary packages as wellâgo ahead and load them all so that everything works as intended.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
sns.set()

import requests
import json
import ast
from bs4 import BeautifulSoup
from datetime import datetime&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the OpenDataPhilly.org website we can find Employee Earnings data by quarter, which has be provided with API access for us to use. We start by defining the URL to access the data. If you look at the URL, you will see the raw JSON. The requests package gets this JSON data and we next parse the JSON into the variable &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;URL = &amp;#39;https://phl.carto.com/api/v2/sql?q=SELECT%20*%20FROM%20employee_earnings&amp;#39;
page = requests.get(URL)
j_data = page.content
data = json.loads(j_data)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Letâs look at the variable &lt;code&gt;data&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# let&amp;#39;s look at the variable data
type(data)

# we see that is a dict
# looking at the keys, we see there are &amp;#39;rows&amp;#39;, &amp;#39;time&amp;#39;, &amp;#39;fields&amp;#39;, and &amp;#39;total_rows&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;dict&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data.keys()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dict_keys([&amp;#39;rows&amp;#39;, &amp;#39;time&amp;#39;, &amp;#39;fields&amp;#39;, &amp;#39;total_rows&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that is of type dict with the keys ârowsâ, âtimeâ, âfieldsâ, and âtotal_rowsâ. Rows seems relevant to our needs, and we can confirm this by looking at a single observation.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# rows seem like what we&amp;#39;ll need
print(data[&amp;#39;rows&amp;#39;][0])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## {&amp;#39;cartodb_id&amp;#39;: 1, &amp;#39;the_geom&amp;#39;: None, &amp;#39;the_geom_webmercator&amp;#39;: None, &amp;#39;calendar_year&amp;#39;: 2021, &amp;#39;quarter&amp;#39;: 3, &amp;#39;last_name&amp;#39;: &amp;#39;Manko Jr&amp;#39;, &amp;#39;first_name&amp;#39;: &amp;#39;Theodore&amp;#39;, &amp;#39;title&amp;#39;: &amp;#39;Detective&amp;#39;, &amp;#39;job_code&amp;#39;: &amp;#39;6A12&amp;#39;, &amp;#39;department_name&amp;#39;: &amp;#39;PPD Police&amp;#39;, &amp;#39;department_number&amp;#39;: &amp;#39;11&amp;#39;, &amp;#39;base_salary&amp;#39;: 85901, &amp;#39;salary_type&amp;#39;: &amp;#39;Salaried&amp;#39;, &amp;#39;overtime_gross_pay_qtd&amp;#39;: 1110.82, &amp;#39;base_gross_pay_qtd&amp;#39;: 23039.1, &amp;#39;longevity_gross_pay_qtd&amp;#39;: 2096.58, &amp;#39;post_separation_gross_pay_qtd&amp;#39;: None, &amp;#39;miscellaneous_gross_pay_qtd&amp;#39;: 7782.08, &amp;#39;employee_category&amp;#39;: &amp;#39;Civil Service&amp;#39;, &amp;#39;compulsory_union_code&amp;#39;: &amp;#39;P&amp;#39;, &amp;#39;termination_month&amp;#39;: None, &amp;#39;termination_year&amp;#39;: None, &amp;#39;public_id&amp;#39;: 5610}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# pull this into a pandas dataframe
df = pd.DataFrame(data[&amp;#39;rows&amp;#39;])
df.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    cartodb_id the_geom  ... termination_year  public_id
## 0           1     None  ...              NaN       5610
## 1           2     None  ...              NaN        319
## 2           3     None  ...              NaN      21446
## 3           4     None  ...              NaN      29891
## 4           5     None  ...           2021.0      14611
## 
## [5 rows x 23 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Great, we now have the beginning of our data set. Letâs take a look at what we have.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# we have 23 columns and over 316,000 observations
df.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 316304 entries, 0 to 316303
## Data columns (total 23 columns):
##  #   Column                         Non-Null Count   Dtype  
## ---  ------                         --------------   -----  
##  0   cartodb_id                     316304 non-null  int64  
##  1   the_geom                       0 non-null       object 
##  2   the_geom_webmercator           0 non-null       object 
##  3   calendar_year                  316304 non-null  int64  
##  4   quarter                        316304 non-null  int64  
##  5   last_name                      316304 non-null  object 
##  6   first_name                     316304 non-null  object 
##  7   title                          316304 non-null  object 
##  8   job_code                       316304 non-null  object 
##  9   department_name                316304 non-null  object 
##  10  department_number              316304 non-null  object 
##  11  base_salary                    300770 non-null  float64
##  12  salary_type                    316303 non-null  object 
##  13  overtime_gross_pay_qtd         164753 non-null  float64
##  14  base_gross_pay_qtd             316304 non-null  float64
##  15  longevity_gross_pay_qtd        210186 non-null  float64
##  16  post_separation_gross_pay_qtd  4186 non-null    float64
##  17  miscellaneous_gross_pay_qtd    316304 non-null  float64
##  18  employee_category              316304 non-null  object 
##  19  compulsory_union_code          316303 non-null  object 
##  20  termination_month              33739 non-null   float64
##  21  termination_year               33739 non-null   float64
##  22  public_id                      316304 non-null  int64  
## dtypes: float64(8), int64(4), object(11)
## memory usage: 55.5+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see there are 23 columns and over 316,000 observations. Our variables are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;cartodb_id&lt;/strong&gt;: an index generated by cartodb (where we must have imported the data from)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;the_geom&lt;/strong&gt; and &lt;strong&gt;the_geom_webmercator&lt;/strong&gt;: geographic inforamtion. Not needed for our analysis&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;calendar_year&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;quarter&lt;/strong&gt;: we must have pay info per quarter&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;last_name&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;first_name&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;title&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;job_code&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;department_name&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;department_number&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;base_salary&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;salary_type&lt;/strong&gt; (Salaried or Non-Salaried. We will probably want to explore what the types are and how that affects &lt;code&gt;base_salary&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;overtime_gross_pay_qtd&lt;/strong&gt;: gross overtime pay that quarter&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;base_gross_pay_qtd&lt;/strong&gt;: base salary represented as a quarterly distribution&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;longevtiy_gross_pay_qtd&lt;/strong&gt; (Phila.gov must have some additional pay component reflecting tenure)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;post_separation_gross_pay_qtd&lt;/strong&gt; (it appears Phila.gov will sometimes pay employees that have already left)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;miscellaneous_gross_pay_qtd&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;employee_category&lt;/strong&gt; (what are the categories here?)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;compulsory_union_code&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;termination_month&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;termination_year&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thereâs a lot here! The first few columns are identifiers from the database pull which we donât need to worry about for our analysis. Then we get into year/quarter, employee info including name, title, and department data, and then a bunch of different quarterly pay info. Finally, we have termination date if applicable.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;At this point, I like to save the data to a file on my computer for easy access while I prepare it for analysis. This is not necessary, but ensures that I have the data in case anything happens to the source.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.to_csv(path_or_buf=f&amp;quot;{datetime.now().strftime(&amp;#39;%Y-%m-%d&amp;#39;)}_phila_ee_salary_data.csv&amp;quot;, index=False)

# next time when we want to use this data, we can simply load the dataframe df from the csv file instead
# If you do so, un-comment the two lines below to continue following along
 
#df = pd.read_csv(&amp;#39;[YOURDATE]_phila_ee_salary_data.csv&amp;#39;)
#df.reset_index(drop = True, inplace=True)&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;Itâs a bit overwhelming to take this all in, so letâs pare it down to just what weâll need. For our analysis, we will only look at salaried employees. The same employee appears multiple times if theyâve worked for more than one quarter, so lets select just the data from Q4 of 2020. We also want to look only at active employees so we will remove those with a termination date. Then, weâll drop the columns that arenât relevant for us.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# let&amp;#39;s look at salaried employees only
df = df[df.salary_type == &amp;#39;Salaried&amp;#39;]

# we have data from more than one quarter. we want just the data from 2020Q4
df = df[df.calendar_year == 2020] 
df = df[df.quarter == 4]

# we also want only active employees (i.e. those without a termination month or year)
# check that all those with a termination month have a termination year (for data integrity purposes)

# drop any employee that has been terminated
df = df[df.termination_year.isna()]

# let us also drop some columns we know we won&amp;#39;t be using
drop_cols = [&amp;#39;cartodb_id&amp;#39;,
             &amp;#39;the_geom&amp;#39;, 
             &amp;#39;the_geom_webmercator&amp;#39;,
             &amp;#39;calendar_year&amp;#39;,
             &amp;#39;quarter&amp;#39;]

df.drop(drop_cols, axis=1, inplace=True)

df.head(20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             last_name first_name  ... termination_year public_id
## 12             Cooney      James  ...              NaN     34345
## 37             Zucker    Stanley  ...              NaN     24559
## 52             Labree     Martin  ...              NaN     18078
## 57             Biello   Patricia  ...              NaN      5019
## 87              Scott      Karen  ...              NaN     11741
## 98            O Brien     Eileen  ...              NaN     25831
## 123           Johnson      Clyde  ...              NaN     24277
## 152          Krawczyk    Richard  ...              NaN     31965
## 164             Hatch     Steven  ...              NaN      4863
## 189            Nieves      Linda  ...              NaN     34948
## 195          Robinson    Gregory  ...              NaN       980
## 211          Agozzino   Pasquale  ...              NaN     22378
## 216          Reynolds     Denise  ...              NaN     30681
## 229              Mohl      Brian  ...              NaN     11831
## 233  Glinski-Sullivan      Susan  ...              NaN     28036
## 273            Cannon    Theresa  ...              NaN     34725
## 291            Hockel      Peter  ...              NaN     17968
## 299          Mc Grath    Colleen  ...              NaN     31728
## 305          Rucci Jr       Adam  ...              NaN     26865
## 313      Merriweather    Tialynn  ...              NaN     11577
## 
## [20 rows x 18 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So far so good! We have a nice data set that we could use to answer a number of questions already. However, it will be more inciteful for pay equity if we can pull in a few additional variables that may impact pay.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-job-information&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional Job Information&lt;/h2&gt;
&lt;p&gt;We now have a &lt;code&gt;df&lt;/code&gt; with employee pay info but we do not know what the relevant job level and ranges are. We can find this on the phila.gov website. After a bit of digging, I found a page with &lt;a href=&#34;https://www.phila.gov/personnel/Specs.html&#34;&gt;job spec info&lt;/a&gt; online. With a tad of more advanced web scraping which is beyond the scope of this tutorial, I was able to pull the details into a json file which I load below. This file can be found in the github repository for the project as well. Follow along the steps below to clean the file youâve just imported.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: If you follow the link above, youâll notice thereâs a 404 error! When I initially pulled this data in April of 2021, the page was up. However, the Philly webpage must have changed in the meantime. Yet another reason to save a local copy of data acquired through webscraping so that when things change, you donât have to recreate the wheel.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# I have pulled this into a json file which I open here
with open(&amp;#39;2021_04_28_phila_master_data_pull.json&amp;#39;) as fh:
    job_spec_data = json.load(fh)
    
# these are the rows we want for this analysis
data_subset = job_spec_data[12:986]

# we continue to pare down data_subset to just the details we need, in a nice dataframe-like list of dicts
# select just the relevant details (each data in subset is a key-value pair. We only want the value for each row)
for i, data in enumerate(data_subset):
    data_subset[i] = data_subset[i][&amp;#39;jobClassSpecs&amp;#39;]

# this will be the DF we use! job_spec_df
job_spec_df = pd.DataFrame(data_subset)

# take a look at our work
job_spec_df.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   jobClassCode           jobClassTitle payRange  ... flsaCode effectiveDate family
## 0         1A01  Clerical Assistant (S)     0003  ...       1N      6/2/2017      1
## 1         1A02        Office Clerk (B)     0004  ...       1N     4/15/2019      1
## 2         1A03          Office Clerk 2     0006  ...       1N     4/15/2019      1
## 3         1A04             Clerk 3 (S)     0011  ...       1N     5/31/2013      1
## 4         1A18               Secretary     0008  ...       1N      3/8/2019      1
## 
## [5 rows x 9 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the dataframe &lt;code&gt;job_spec_df&lt;/code&gt; we have the following variables:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;jobClassCode&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jobClassCode&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jobClassTitle&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;payRange&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jobClassSalaryMin&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;jobClassSalaryMax&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;unionCode&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;flsaCode&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;effectiveDate&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;family&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The final step is to cast the data objects to the types we expect them to be.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# cast the dtypes to the correct dtype
job_spec_df[&amp;#39;effectiveDate&amp;#39;] = pd.to_datetime(job_spec_df[&amp;#39;effectiveDate&amp;#39;])
job_spec_df[&amp;#39;family&amp;#39;] = job_spec_df[&amp;#39;family&amp;#39;].astype(str)
job_spec_df[&amp;#39;jobClassSalaryMin&amp;#39;] = job_spec_df[&amp;#39;jobClassSalaryMin&amp;#39;].astype(float)
job_spec_df[&amp;#39;jobClassSalaryMax&amp;#39;] = job_spec_df[&amp;#39;jobClassSalaryMax&amp;#39;].astype(float)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;imputing-gender-information&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Imputing gender information&lt;/h2&gt;
&lt;p&gt;We have successfully gathered information on employee pay, job title, department, job type, union info and more. Working with a company, however, this is not necessarily riveting information. More often companies are interested in how demographics such as sex or race may affect these at an organizational level. For the purpose of this example, we take a guess an employeeâs biological sex to give us a mock data set.&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;Here it is worth reiterating that there are huge issues with doing this type of guesswork in a real world setting. Furthermore, we cannot use the analysis here to make any claims about the City of Philadelphiaâs actual pay practices. In this data set, employee gender is entirely a guess and we are not looking at gender non-conforming individuals. &lt;em&gt;However&lt;/em&gt; for the purposes of this exercise, I am happy with the number of observations and pretend gender. Now, we can attempt to determine pay inequity across gender based on this hypothetical data set. &lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;Another approach would have been to randomly assign gender to each observation in our data set, but I did not want to know ahead of time what the distributions would be. So, letâs jump into it.&lt;/p&gt;
&lt;p&gt;We want a simple way of guessing at an employeeâs gender. To do this, we will parse a list of the 100 most common names by sex and cross reference it with our list of employees using the &lt;code&gt;BeautifulSoup&lt;/code&gt; package. We use data on &lt;a href=&#34;https://www.ssa.gov/oact/babynames/decades/century.html&#34;&gt;Popular names for births in 1921-2020&lt;/a&gt; to help our guesses. Take a look at webpageâyou can see a list with each of the most popular names by sex side by side. Looking at the html, we can see a clear pattern of where each name appears. This will make our web scraping easier.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;NAMES_URL = &amp;#39;https://www.ssa.gov/oact/babynames/decades/century.html&amp;#39;
names_page = requests.get(NAMES_URL)

soup = BeautifulSoup(names_page.content, &amp;#39;html.parser&amp;#39;)
body = soup.tbody&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;body&lt;/code&gt; contains parsed html. Using the &lt;code&gt;find.all&lt;/code&gt; method we can grab each of the popular names and assign them to a corresponding list by sex.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#initialize our lists
male_names = []
female_names = []

for line in body.find_all(&amp;#39;tr&amp;#39;):
    for i, item in enumerate(line.find_all(&amp;#39;td&amp;#39;)):
        if i==1:
            male_names.append(item.text)
        elif i==3:    
            female_names.append(item.text)

# for male_names, the scaper captures an extra line with source info. We don&amp;#39;t need this in our list
male_names = male_names[:100]
print(male_names)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [&amp;#39;James&amp;#39;, &amp;#39;Robert&amp;#39;, &amp;#39;John&amp;#39;, &amp;#39;Michael&amp;#39;, &amp;#39;William&amp;#39;, &amp;#39;David&amp;#39;, &amp;#39;Richard&amp;#39;, &amp;#39;Joseph&amp;#39;, &amp;#39;Thomas&amp;#39;, &amp;#39;Charles&amp;#39;, &amp;#39;Christopher&amp;#39;, &amp;#39;Daniel&amp;#39;, &amp;#39;Matthew&amp;#39;, &amp;#39;Anthony&amp;#39;, &amp;#39;Mark&amp;#39;, &amp;#39;Donald&amp;#39;, &amp;#39;Steven&amp;#39;, &amp;#39;Paul&amp;#39;, &amp;#39;Andrew&amp;#39;, &amp;#39;Joshua&amp;#39;, &amp;#39;Kenneth&amp;#39;, &amp;#39;Kevin&amp;#39;, &amp;#39;Brian&amp;#39;, &amp;#39;George&amp;#39;, &amp;#39;Edward&amp;#39;, &amp;#39;Ronald&amp;#39;, &amp;#39;Timothy&amp;#39;, &amp;#39;Jason&amp;#39;, &amp;#39;Jeffrey&amp;#39;, &amp;#39;Ryan&amp;#39;, &amp;#39;Jacob&amp;#39;, &amp;#39;Gary&amp;#39;, &amp;#39;Nicholas&amp;#39;, &amp;#39;Eric&amp;#39;, &amp;#39;Jonathan&amp;#39;, &amp;#39;Stephen&amp;#39;, &amp;#39;Larry&amp;#39;, &amp;#39;Justin&amp;#39;, &amp;#39;Scott&amp;#39;, &amp;#39;Brandon&amp;#39;, &amp;#39;Benjamin&amp;#39;, &amp;#39;Samuel&amp;#39;, &amp;#39;Gregory&amp;#39;, &amp;#39;Frank&amp;#39;, &amp;#39;Alexander&amp;#39;, &amp;#39;Raymond&amp;#39;, &amp;#39;Patrick&amp;#39;, &amp;#39;Jack&amp;#39;, &amp;#39;Dennis&amp;#39;, &amp;#39;Jerry&amp;#39;, &amp;#39;Tyler&amp;#39;, &amp;#39;Aaron&amp;#39;, &amp;#39;Jose&amp;#39;, &amp;#39;Adam&amp;#39;, &amp;#39;Henry&amp;#39;, &amp;#39;Nathan&amp;#39;, &amp;#39;Douglas&amp;#39;, &amp;#39;Zachary&amp;#39;, &amp;#39;Peter&amp;#39;, &amp;#39;Kyle&amp;#39;, &amp;#39;Walter&amp;#39;, &amp;#39;Ethan&amp;#39;, &amp;#39;Jeremy&amp;#39;, &amp;#39;Harold&amp;#39;, &amp;#39;Keith&amp;#39;, &amp;#39;Christian&amp;#39;, &amp;#39;Roger&amp;#39;, &amp;#39;Noah&amp;#39;, &amp;#39;Gerald&amp;#39;, &amp;#39;Carl&amp;#39;, &amp;#39;Terry&amp;#39;, &amp;#39;Sean&amp;#39;, &amp;#39;Austin&amp;#39;, &amp;#39;Arthur&amp;#39;, &amp;#39;Lawrence&amp;#39;, &amp;#39;Jesse&amp;#39;, &amp;#39;Dylan&amp;#39;, &amp;#39;Bryan&amp;#39;, &amp;#39;Joe&amp;#39;, &amp;#39;Jordan&amp;#39;, &amp;#39;Billy&amp;#39;, &amp;#39;Bruce&amp;#39;, &amp;#39;Albert&amp;#39;, &amp;#39;Willie&amp;#39;, &amp;#39;Gabriel&amp;#39;, &amp;#39;Logan&amp;#39;, &amp;#39;Alan&amp;#39;, &amp;#39;Juan&amp;#39;, &amp;#39;Wayne&amp;#39;, &amp;#39;Roy&amp;#39;, &amp;#39;Ralph&amp;#39;, &amp;#39;Randy&amp;#39;, &amp;#39;Eugene&amp;#39;, &amp;#39;Vincent&amp;#39;, &amp;#39;Russell&amp;#39;, &amp;#39;Elijah&amp;#39;, &amp;#39;Louis&amp;#39;, &amp;#39;Bobby&amp;#39;, &amp;#39;Philip&amp;#39;, &amp;#39;Johnny&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our employee data set, we will compare the first name of each employee to see if it appears in either our &lt;code&gt;female_names&lt;/code&gt; list or our &lt;code&gt;male_names&lt;/code&gt; list. If it does, we will assign them a binary value indicating which group they belong to.&lt;/p&gt;
&lt;p&gt;To help with our text comparisons, we want to make all letters lowercase so that capitalizations do not through off our script. Having done this, we iterate through our &lt;code&gt;df&lt;/code&gt; and assign each employee to the variable &lt;code&gt;likely_female&lt;/code&gt; or &lt;code&gt;likely_male&lt;/code&gt;. Those employees who are not categorized by this method will be removed from our data.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# first step will be to standardize lists to lowercase
for i, name in enumerate(male_names):
    male_names[i] = name.lower()

for i, name in enumerate(female_names):
    female_names[i] = name.lower()

df.first_name = df.first_name.str.lower()

# add likely_male and likely female columns to df, where a 1 represents yes and a 0 means no
df[&amp;#39;likely_male&amp;#39;] = np.where(df.first_name.isin(male_names), 1, 0)
df[&amp;#39;likely_female&amp;#39;] = np.where(df.first_name.isin(female_names), 1, 0)

df.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    last_name first_name  ... likely_male likely_female
## 12    Cooney      james  ...           1             0
## 37    Zucker    stanley  ...           0             0
## 52    Labree     martin  ...           0             0
## 57    Biello   patricia  ...           0             1
## 87     Scott      karen  ...           0             1
## 
## [5 rows x 20 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Letâs see how well our matching process did.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# it appears we were able to guess about 50% of employees&amp;#39; gender
sum_males = sum(df[&amp;#39;likely_male&amp;#39;])
sum_females = sum(df[&amp;#39;likely_female&amp;#39;])

print(&amp;#39;Count of likely males: &amp;#39; + str(sum_males))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Count of likely males: 10500&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;#39;Count of likely females: &amp;#39; + str(sum_females))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Count of likely females: 3572&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;#39;Total likely matches: &amp;#39; + str(sum_males + sum_females))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Total likely matches: 14072&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;#39;Total observations in df: &amp;#39; + str(len(df)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Total observations in df: 28201&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;#39;Percentage counted: &amp;#39; + str(np.round((sum_males + sum_females) / len(df) * 100,2)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Percentage counted: 49.9&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;bringing-it-all-together&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bringing it all together&lt;/h2&gt;
&lt;p&gt;We have imputed sex information for about half of the employees in our data. Since we have a pretty high n, letâs just toss out those who donât have sex info. Again, in a real organization, you would have this detail in your records so you would never face this issue.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# include just the observations of salaried employee that we have gender info for
df = df[(df[&amp;#39;likely_female&amp;#39;] == 1) | (df[&amp;#39;likely_male&amp;#39;] == 1)]

print(len(df))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 14072&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now just need to select the columns we will be using in our pay equity analysis, join the job level data we compiled in &lt;code&gt;job_spec_df&lt;/code&gt;, and weâll be good to go!&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df = df[[&amp;#39;last_name&amp;#39;,
          &amp;#39;first_name&amp;#39;,
          &amp;#39;title&amp;#39;,
          &amp;#39;job_code&amp;#39;,
          &amp;#39;department_name&amp;#39;,
          &amp;#39;department_number&amp;#39;,
          &amp;#39;base_salary&amp;#39;,
          &amp;#39;likely_male&amp;#39;,
          &amp;#39;likely_female&amp;#39;]]


# Now we have dataframe df which has employee data. we want to add payRange, jobClassSalaryMin, and jobClassSalaryMax to the data set
# mapped as job_code = jobClassCode

combined_df = df.merge(job_spec_df, how=&amp;#39;left&amp;#39;, left_on=&amp;#39;job_code&amp;#39;, right_on=&amp;#39;jobClassCode&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, letâs take a look at the shape of our data and save to a file for our analysis.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_to_save = combined_df.dropna()

print(df_to_save.shape)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (10778, 18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_to_save.to_csv(&amp;#39;MVR_preprocessed_data.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;In part one of this Pay Equity Analysis tutorial, we pulled together the the necessary salary data using Phillyâs Open Data API. We then cleaned our job level data to help color our analysis. Finally, we flexed our web scraping muscles to impute sex data and combined with our employee pay data. We are now all set to do the actual pay equity analysis! You can find part two (coming soon) here.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: January 18, 2022&lt;/font&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why Remote Work Won&#39;t Lead to Lower Salaries</title>
      <link>https://iopsychist.netlify.app/post/remote-work-salary-trends/</link>
      <pubDate>Tue, 11 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/remote-work-salary-trends/</guid>
      <description>&lt;p&gt;While I am a few days late on this 2022 prediction, this blog was only an idea 10 days ago so please be generous. Truth be had, however, I first wrote this prediction (albeit privately) on 12/24/21, clearly ahead of the New Year&amp;rsquo;s Eve deadline. So, what do I predict? &lt;mark&gt;In 2022, we are going to see average salaries rise in non-peak markets in the United States due to remote friendly jobs.&lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;When the pandemic first began, cities like San Francisco and New York saw an exodus. Employees with newfound flexibility realized that the city was no longer fun during lockdown, so why not be somewhere with more space and more things to do at a percentage of the cost? Initially, companies still holding to the traditional ways of thinking announced that location-based wage adjustments would be conducted for those who decided to &lt;a href=&#34;https://www.reuters.com/world/the-great-reboot/pay-cut-google-employees-who-work-home-could-lose-money-2021-08-10/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;move away from the cities permanently&lt;/a&gt;. Almost as soon, however, other companies realized that not cutting wages for remote workers could form a competitive advantage in the competition for talent. Reddit, for example, &lt;a href=&#34;https://www.redditinc.com/blog/evolving-reddits-workforce/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eliminated geographic compensation zones in the US&lt;/a&gt;. Overall, however, the wisdom of the crowds still thought that pay would decrease for workers who moved away from the city.&lt;/p&gt;
&lt;p&gt;Fast forward to the beginning of 2022, almost 2 years into the pandemic. The return to the office was not a quick as we thought with the Delta and now Omicron waves halting our progress back to carefree in-person activities. The &amp;lsquo;Great Resignation&amp;rsquo; seen in 2021 is now being seen more accurately as the &lt;a href=&#34;https://www.bbc.com/worklife/article/20211214-great-resignation-into-great-reshuffle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;lsquo;Great Reshuffle&amp;rsquo;&lt;/a&gt;. In November, job openings surpassed total separations (which not only includes employees who quit, but also those who were fired, laid off, or otherwise separated from their employer) &lt;a href=&#34;https://www.bls.gov/news.release/jolts.nr0.htm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;by almost 1.7X&lt;/a&gt;. Despite largely being remote for the better part of 2 years, many companies are seeing &lt;a href=&#34;https://www.wsj.com/articles/how-the-biggest-companies-have-fared-during-the-covid-19-pandemic-11630229403&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;higher revenues&lt;/a&gt; than before the pandemic. Instead of hindering efficiency, remote work has so far stood the test and companies seeing a need to hire are now feeling pressure to fill openings in a candidate&amp;rsquo;s market.&lt;/p&gt;
&lt;p&gt;Americans are &lt;a href=&#34;https://www.wsj.com/articles/pandemic-supercharged-changes-in-where-americans-live-11619536399&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;moving out of big, expensive cities&lt;/a&gt; into more affordable locations. This movement however, isn&amp;rsquo;t changing the talent pool in the same way it would have before the pandemic. Employers looking for any edge they can get in the struggle to attract talent are looking further afield than pre-pandemic as well (i.e remote). According to PayScale&amp;rsquo;s 2021 State of Remote Work Report, &lt;a href=&#34;https://www.payscale.com/research-and-insights/remote-work/#remote-report&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;employees who work remotely donât earn less compensation&lt;/a&gt;. For companies that are a) seeing higher revenues and b) looking to attract top talent, the calculations will result in a simple solution &amp;ndash; &lt;strong&gt;continue to pay to the highest geo-location&lt;/strong&gt; they operate in. This means that companies in New York or the Bay Area will offer the same salary to remote employees as they offer to in-person or hybrid employees. Top talent in any market will be attracted to the salaries offered by these companies, forcing smaller companies and those not located to peak cities to compete with peak city wages, whether they like it or not.&lt;/p&gt;
&lt;p&gt;2022 will (hopefully) see the end of the pandemic, however some things will never go back to the way they were. Expect to see wages rises in secondary and tertiary locations as the effects of the great reshuffle continue to ripple through the world of work.&lt;/p&gt;
&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: January 11, 2022&lt;/font&gt;</description>
    </item>
    
    <item>
      <title>Configuring an SSH connection in Jupyter Notebooks</title>
      <link>https://iopsychist.netlify.app/post/configuring-an-ssh-connection-in-jupyter-notebooks/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/configuring-an-ssh-connection-in-jupyter-notebooks/</guid>
      <description>&lt;p&gt;Sometimes, the database you want to connect a Jupyter Notebook to is  located behind an SSH tunnel. Using the files here, you can set establish the SSH connection and connect to the database all from within Python.&lt;/p&gt;
&lt;p&gt;I have this set up such that both the config file and the connector methods are separate from the Python script you are working in. However, you can also copy the mypython_dbconnector.py file into a Jupyter Notebook and not worry about importing it. I like the separation to keep the ipynb file clean. &lt;em&gt;Note:&lt;/em&gt; this code is adapted from &lt;a href=&#34;https://practicaldatascience.co.uk/data-science/how-to-connect-to-mysql-via-an-ssh-tunnel-in-python&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://practicaldatascience.co.uk/data-science/how-to-connect-to-mysql-via-an-ssh-tunnel-in-python&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;create-the-functions-we-will-use&#34;&gt;Create the functions we will use&lt;/h2&gt;
&lt;p&gt;We need to define a few functions for easily connecting to the database. In this case, we are connecting to a MySQL database so we use the Python package &lt;code&gt;pymysql&lt;/code&gt;. This can easily be changed to a different database if your needs require.&lt;/p&gt;
&lt;p&gt;Create a file mypython_dbconnector.py with the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import pandas as pd
import matplotlib.pyplot as plt
import pymysql
import logging
import sshtunnel
from sshtunnel import SSHTunnelForwarder

import config


# define the functions we will be using

def open_ssh_tunnel(verbose=False):
    &amp;quot;&amp;quot;&amp;quot;Open an SSH tunnel and connect using a username and password.
    
    :param verbose: Set to True to show logging
    :return tunnel: Global SSH tunnel connection
    &amp;quot;&amp;quot;&amp;quot;
    
    if verbose:
        sshtunnel.DEFAULT_LOGLEVEL = logging.DEBUG
    
    global tunnel
    tunnel = SSHTunnelForwarder(
        (config.ssh_host, 22),
        ssh_username = config.ssh_username,
        ssh_password = config.ssh_password,
        remote_bind_address = (&#39;127.0.0.1&#39;, 3306)
    )
    
    tunnel.start()
    
    
def mysql_connect():
    &amp;quot;&amp;quot;&amp;quot;Connect to a MySQL server using the SSH tunnel connection
    
    :return connection: Global MySQL database connection
    &amp;quot;&amp;quot;&amp;quot;
    
    global connection
    
    connection = pymysql.connect(
        host=&#39;127.0.0.1&#39;,
        user=config.database_username,
        password=config.database_password,
        database=config.database_name,
        port=tunnel.local_bind_port
    )
    

def run_query(sql):
    &amp;quot;&amp;quot;&amp;quot;Runs a given SQL query via the global database connection.
    
    :param sql: MySQL query
    :return: Pandas dataframe containing results
    &amp;quot;&amp;quot;&amp;quot;
    
    return pd.read_sql_query(sql, connection)


def mysql_disconnect():
    &amp;quot;&amp;quot;&amp;quot;Closes the MySQL database connection.
    &amp;quot;&amp;quot;&amp;quot;
    
    connection.close()
    
    
def close_ssh_tunnel():
    &amp;quot;&amp;quot;&amp;quot;Closes the SSH tunnel connection.
    &amp;quot;&amp;quot;&amp;quot;
    
    tunnel.close

&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;warning&#34; style=&#34;background-color:lightyellow&#34;&gt;
&lt;i&gt;Note:&lt;/i&gt; saving this file as dbconnector.py may interfere with other packages in your environment and lead to unexpected behaviors.
&lt;/div&gt;
&lt;h2 id=&#34;create-the-config-file-with-our-connection-credentials&#34;&gt;Create the config file with our connection credentials&lt;/h2&gt;
&lt;p&gt;Next, we need to provide python with the credentials to connect. I like to define these in a separate file so that I can share the actual Jupyter notebook with my work and not have to worry about security. Enter your usernames and passwords in the file below and save it as &lt;code&gt;config.py&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
# Standard TCP/IP

# may need to change this depending on your tunnel connection details
ssh_host = &#39;128.122.34.205&#39;
# port 22 by default

ssh_username = &#39;SSH_USERNAME&#39;
ssh_password = &#39;SSH_PASSWORD&#39;

database_name = &#39;YOUR_DATABASE_NAME&#39;
localhost = &#39;127.0.0.1&#39;
# port 3306 by default

database_username = &#39;YOUR_USERNAME&#39;
database_password = &#39;YOUR_PASSWORD&#39;

&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;connect-to-the-database-and-get-to-work&#34;&gt;Connect to the database and get to work!&lt;/h2&gt;
&lt;p&gt;Finally, we are ready to connect and start working with our data. Make sure both the files we just created are in the same directory and then create a new Jupyter Notebook file in the same location.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

import mypython_dbconnector

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We start with the imports we will be using for our work, along with importing our file &lt;code&gt;mypthon_dbconnector.py&lt;/code&gt;. Now, all we need to do is call the functions we defined earlier. We then pass our sql query as a string to our &lt;code&gt;run_query()&lt;/code&gt; command and save the return value to a dataframe. Rinse and repeat as necessary!&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# connect to ssh tunnel and to mysql db
mypython_dbconnector.open_ssh_tunnel()
mypython_dbconnector.mysql_connect()

# define query
query = &#39;&#39;&#39;
SELECT
    *
FROM
    table_name
&#39;&#39;&#39;

df = mypython_dbconnector.run_query(query)

# your data analysis here
# TODO

# close mysql connection and close ssh tunnel
mypython_dbconnector.mysql_disconnect()
mypython_dbconnector.close_ssh_tunnel()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you are connected to the database through the ssh tunnel, you can access it a you normally would. Be sure to disconnect from the database and close the SSH tunnel when you are done working with it. The full directory setup with example jupyter notebook can be found at &lt;a href=&#34;https://github.com/eli-jaffe/ssh_mysql_connect&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/eli-jaffe/ssh_mysql_connect&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Opening a New Position</title>
      <link>https://iopsychist.netlify.app/post/opening-a-new-position/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/opening-a-new-position/</guid>
      <description>&lt;p&gt;When a new position is opened, the hiring manager should be able to express the why, the what, the when, and the where behind the position. This includes the reason the position is being requested, what the position will be responsible for and what projects the incumbent will likely be part of, when the position will be needed and the hours per week the position will require, and where the position will need to be located, among other relevant details to the position.&lt;/p&gt;
&lt;p&gt;Being able to explain these aspects up front is important for a few reasons. It ensures the position (and, therefore, the need for the position) has been carefully considered and determined to be appropriate. The recruitment process requires significant time, energy, and money from the hiring team, the recruiting team, and candidates. If there is not a clear reason for the position, it should be reconsidered whether the role is necessary at the current time. Furthermore, hiring and onboarding a new employee requires time, resources, and has potential long-term impact for the company â good or bad. While it may be tempting to bring on additional help as needed, answering these questions up front will ensure that the benefits and costs are appropriately weighed.&lt;/p&gt;
&lt;p&gt;Tactically, being able to communicate these questions at the beginning of the process to the recruiting team will greatly improve the efficiency and effectiveness of the recruiting process. With a clear understanding of the need to have and nice to have aspects of the position, as well as the fit within the organization, the recruiting team is able to more accurately source and evaluate candidates.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Think of the hiring process like searching for a car to buy.&lt;/strong&gt; You (the hiring manager) may know you want a good commuter car that can hold your family comfortably. This would be equivalent to knowing the job title of the opening. If you were to ask someone to find you the right car for your needs, there would be quite a range of options for them to select â likely some which youâre not interested in. Furthermore, once youâve narrowed your search down to a specific make/model (say, after youâve reviewed a few âcandidate carsâ or done further research), there are still more details that are important. Do you want new or used? What color interior or exterior? Do you want to spring for some of the enhanced features? All of them? None of them? So, while you started with what may be thought of as a well-defined need (i.e. commuter car that can hold your family), we see that there are actually numerous other details to consider. Imagine if you provided preferences on the color, new vs used, perhaps even the make and model up front. There would still be details to choose between of course (based on whatâs available on the market in your area at the time of your search) but you would have sped up the selection process considerably, possibly giving you access to cars available on the market that you might have been too late for with the previous approach. Now, imagine that you are searching for 50 cars a year, and you are losing money each day that the search lasts. This is why detailed requests &lt;em&gt;up front&lt;/em&gt; are important.&lt;/p&gt;
&lt;p&gt;To facilitate this, when a new position is opened, the recruiter (or coordinator) responsible for working on the position should have an intake discussion with the hiring manager. Using the example intake form below, they will be able to review the position details and align on the needs of the hiring manager. While not all the possible questions may be answerable up front, and while things may change over the course of the recruiting process, the team should aim as much as possible for accuracy and completeness of these answers. Also, keep in mind that the recruiter will need to be able to describe the opening to candidates and build up excitement for the opportunity. Completing the intake will save the company money, enhance the quality of candidates and hires, and increase the velocity of hiring.&lt;/p&gt;
&lt;h3 id=&#34;example-new-job-intake-form&#34;&gt;Example New Job Intake Form&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Role and Responsibilities&lt;/em&gt;&lt;br&gt;
What will this person be doing?&lt;br&gt;
Need to haves?&lt;br&gt;
Nice to haves?&lt;br&gt;
Specific projects they can expect to work on?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Candidate Details&lt;/em&gt;&lt;br&gt;
Target candidate profile?&lt;br&gt;
Anti-patterns to watch out for?&lt;br&gt;
Possible career paths?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Position details&lt;/em&gt;&lt;br&gt;
Backfill or new position?&lt;br&gt;
Location:&lt;br&gt;
Hours:&lt;br&gt;
Pay:&lt;br&gt;
When is this position targeted to come onboard:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Team details&lt;/em&gt;&lt;br&gt;
Who do they report to?&lt;br&gt;
How big is the current team? &lt;br&gt;
Management/supervisory duties?&lt;br&gt;
Who else will this person interact with regularly?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Looking back on a successful hire, what will this new hire have done to be considered as such in the first&amp;hellip;&lt;/em&gt;&lt;br&gt;
30 days?&lt;br&gt;
90 days?&lt;br&gt;
Year?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Interview process&lt;/em&gt;&lt;br&gt;
What will the typical interview process look like for this position?&lt;br&gt;
Who is part of the interview team?&lt;br&gt;
What will each of them be looking at?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How to sell the role&lt;/em&gt;&lt;br&gt;
Why would someone choose this position over another option?&lt;/p&gt;
&lt;p&gt;Anything else that will be important for (Recruiter or RC) to know as they review and screen candidates?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;br&gt;
Incorporating the intake form (whether this specific one or something similar) will pay dividends for your recruiting game. You will notice the difference almost immediately!  
&lt;/br&gt;
&lt;br&gt;
&lt;font color=&#34;grey&#34;&gt; Originally posted: January 10, 2022&lt;/font&gt;</description>
    </item>
    
    <item>
      <title>Resources: Databases</title>
      <link>https://iopsychist.netlify.app/post/resources-databases/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/resources-databases/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve gathered a number of resources which have helped me at various stages in my journey into databases. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Relational DB Design&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www3.ntu.edu.sg/home/ehchua/programming/sql/Relational_Database_Design.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www3.ntu.edu.sg/home/ehchua/programming/sql/Relational_Database_Design.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Building RDB from CSV files&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/how-to-build-a-relational-database-from-csv-files-using-python-and-heroku-20ea89a55c63&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://towardsdatascience.com/how-to-build-a-relational-database-from-csv-files-using-python-and-heroku-20ea89a55c63&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10 DB Desgin best practices&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://medium.com/quick-code/10-best-database-design-practices-1f10f3441730&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/quick-code/10-best-database-design-practices-1f10f3441730&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;using jupyter and SQL&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.datacamp.com/community/tutorials/beginners-introduction-postgresql&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.datacamp.com/community/tutorials/beginners-introduction-postgresql&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using PostgreSQL through SQLalchemy&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.compose.com/articles/using-postgresql-through-sqlalchemy/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.compose.com/articles/using-postgresql-through-sqlalchemy/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Using Databases with Python: Postgres, SQLAlchemy, and Alembic&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.learndatasci.com/tutorials/using-databases-python-postgres-sqlalchemy-and-alembic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.learndatasci.com/tutorials/using-databases-python-postgres-sqlalchemy-and-alembic/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ebook on sql querying&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://use-the-index-luke.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://use-the-index-luke.com/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ERD database modeling tool&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://erdplus.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://erdplus.com/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Building a Data Warehouse in Python using PostgreSQL&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/building-a-data-warehouse-in-python-using-postgresql-77a42e38bd19&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://towardsdatascience.com/building-a-data-warehouse-in-python-using-postgresql-77a42e38bd19&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Curation Network Primers&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/DataCurationNetwork/data-primers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/DataCurationNetwork/data-primers&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;font color=&#34;grey&#34;&gt; Originally posted: January 10, 2022&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resources: People Analytics</title>
      <link>https://iopsychist.netlify.app/post/resources-people-analytics/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/resources-people-analytics/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve gathered a number of resources which have helped me at various stages in my journey into People Analytics. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;th&gt;Note&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;r/IO Programming Starter Kit&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://docs.google.com/document/u/0/d/1OZih--8wujuAdyxln5uvrRHOZQBvjI4pN6VHjPY5d_0/mobilebasic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://docs.google.com/document/u/0/d/1OZih--8wujuAdyxln5uvrRHOZQBvjI4pN6VHjPY5d_0/mobilebasic&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Compensation Analytics Dashboard in Tableau&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://public.tableau.com/profile/luisbatista#!/vizhome/HRAnalyticsDashboard_16097240839050/Compensation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://public.tableau.com/profile/luisbatista#!/vizhome/HRAnalyticsDashboard_16097240839050/Compensation&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Analyzing National Salary Equity in R with Tidyverse&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.airweb.org/article/2019/04/17/analyzing-national-salary-equity-in-r-with-tidyverse&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.airweb.org/article/2019/04/17/analyzing-national-salary-equity-in-r-with-tidyverse&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Glassdoor Report Analyzing Gender Pay Gap&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.glassdoor.com/research/app/uploads/sites/2/2019/03/GD_Report_AnalyzingGenderPayGap_v2-2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.glassdoor.com/research/app/uploads/sites/2/2019/03/GD_Report_AnalyzingGenderPayGap_v2-2.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Empath&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/Ejhfast/empath-client&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Ejhfast/empath-client&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;From the author: Empath is a Python library for analyzing text data, something I&amp;rsquo;ve been working a lot with lately. It&amp;rsquo;s a tool that can generate and validate new lexical categories on demand through deep learning and a corpus of more than 1.8 billion words. What&amp;rsquo;s cool about it is that it was built to be a reverse-engineered version of the Linguistic Inquiry and Word Count [LIWC], which has been used for psychometric applications and research. You can read more about LIWC here, and the Empath whitepaper can also be found here.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Skills for Reproducible Research&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://psyteachr.github.io/reprores-v2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://psyteachr.github.io/reprores-v2/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Github of a Dr in IO Psych - lots of R resources&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/jeromyanglim/r-vandenberghe-exercise&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/jeromyanglim/r-vandenberghe-exercise&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&amp;lt;- this link is EFA specific example but click around and find out&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EFA and CFA tutorials&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Psychometric open dataset&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://openpsychometrics.org/_rawdata/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://openpsychometrics.org/_rawdata/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Investing in People Online&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://orgtools.shinyapps.io/IIP3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://orgtools.shinyapps.io/IIP3/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&amp;lt;&amp;ndash; calculator for employee separations (turnover)  absenteeism  health and welfare  attitudes and engagement  workplace flexibility programs  staffing utility  payoffs from improved selection  payoffs from training and development&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;How to Analyze the Gender Pay Gap&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.glassdoor.com/research/app/uploads/sites/2/2019/03/GD_Report_AnalyzingGenderPayGap_v2-2.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.glassdoor.com/research/app/uploads/sites/2/2019/03/GD_Report_AnalyzingGenderPayGap_v2-2.pdf&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Grabbing and Analyzing Pay Data with Python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/a-beginners-guide-to-grabbing-and-analyzing-salary-data-in-python-e8c60eab186e&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://towardsdatascience.com/a-beginners-guide-to-grabbing-and-analyzing-salary-data-in-python-e8c60eab186e&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Re:Work (ie Google) guide to pay equity analysis&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://rework.withgoogle.com/guides/pay-equity/steps/analyze-the-data-and-look-for-variance/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://rework.withgoogle.com/guides/pay-equity/steps/analyze-the-data-and-look-for-variance/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Network Analysis for Business Performance webinar series - focuses on overview as well as UCINET software&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://connectedcommons.com/network-analysis-for-business-performance/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://connectedcommons.com/network-analysis-for-business-performance/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Handbook of Regression Modeling in People Analytics&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://peopleanalytics-regression-book.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://peopleanalytics-regression-book.org/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;font color=&#34;grey&#34;&gt; Originally posted: January 10, 2022&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resources: Python</title>
      <link>https://iopsychist.netlify.app/post/resources-python/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/resources-python/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve gathered a number of resources which have helped me at various stages in my journey into Python and programming. By and large, the order in which they are presented reflects when I came into contact with them. All of them helped my understanding in some way. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Python101 by Mike Driscoll&amp;ndash;very helpful when just starting out. Occasionallly there are promos for free access&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://leanpub.com/py101&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://leanpub.com/py101&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python/dash&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://coolsciencey.com/covid-dash-sciencey/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://coolsciencey.com/covid-dash-sciencey/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;JPEG Image Scanning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Debugging&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://martinheinz.dev/blog/24&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://martinheinz.dev/blog/24&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Beginner to Intermediate&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://learnbyexample.github.io/curated-resources/python-intermediate/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://learnbyexample.github.io/curated-resources/python-intermediate/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Collection Of Data Science Resources&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.theclickreader.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.theclickreader.com/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;docker container&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.pybootcamp.com/blog/how-to-containerize-python-application/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.pybootcamp.com/blog/how-to-containerize-python-application/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Robinhood API tutorial&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://youtu.be/C5buU4zjjx0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://youtu.be/C5buU4zjjx0&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;nbdev&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.fast.ai/2019/12/02/nbdev/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.fast.ai/2019/12/02/nbdev/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fast AI course on PyTorch/Deep Learning&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://course.fast.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://course.fast.ai/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;building an android app with Python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/building-android-apps-with-python-part-1-603820bebde8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://towardsdatascience.com/building-android-apps-with-python-part-1-603820bebde8&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Web scraping&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://medium.com/python-in-plain-english/web-scraping-made-easy-with-python-and-chrome-windows-da85a08d54f3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/python-in-plain-english/web-scraping-made-easy-with-python-and-chrome-windows-da85a08d54f3&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Flask - Postgres - Heroku Tutorial&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://blog.arctype.com/postgres-heroku/?utm_campaign=postgres-heroku&amp;amp;utm_medium=blog&amp;amp;utm_source=reddit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.arctype.com/postgres-heroku/?utm_campaign=postgres-heroku&amp;utm_medium=blog&amp;utm_source=reddit&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Exploratory Data Analysis with Python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.theclickreader.com/exploratory-data-analysis-with-python/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.theclickreader.com/exploratory-data-analysis-with-python/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;REST API with Django&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://youtu.be/3DjZzK6IFa0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://youtu.be/3DjZzK6IFa0&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;intermediate python resources&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://learnbyexample.github.io/py_resources/intermediate.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://learnbyexample.github.io/py_resources/intermediate.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;premade plots with python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.python-graph-gallery.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.python-graph-gallery.com/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Turning python script into &amp;lsquo;Real&amp;rsquo; program with system services on linux&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://medium.com/star-gazers/turning-your-python-script-into-a-real-program-cb702e16ed02&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/star-gazers/turning-your-python-script-into-a-real-program-cb702e16ed02&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Visualization in python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://youtu.be/DevfjHOhuFc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://youtu.be/DevfjHOhuFc&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jupiter Notebook viewer with various tutorials&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/lightning-viz/lightning-example-notebooks/blob/master/index.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://nbviewer.jupyter.org/github/lightning-viz/lightning-example-notebooks/blob/master/index.ipynb&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4 hour Python course&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://youtu.be/rfscVS0vtbw&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://youtu.be/rfscVS0vtbw&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data viz py package comparison&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://share.streamlit.io/discdiver/data-viz-streamlit/main/app.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://share.streamlit.io/discdiver/data-viz-streamlit/main/app.py&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Layout Parser&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/Layout-Parser/layout-parser&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Layout-Parser/layout-parser&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3-Way Data Migration between Support Systems&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://tilsupport.wordpress.com/2021/04/10/3-way-data-migration-between-support-systems/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tilsupport.wordpress.com/2021/04/10/3-way-data-migration-between-support-systems/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Python Cheatsheet&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/gto76/python-cheatsheet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/gto76/python-cheatsheet&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Markdown language overview for Jupyter Notebook&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Jupyter Notebook Extensions&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/ipython-contrib/jupyter_contrib_nbextensions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/ipython-contrib/jupyter_contrib_nbextensions&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Encoding Categorical Variables in Python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pbpython.com/categorical-encoding.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://pbpython.com/categorical-encoding.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Progress Bar for iterables python package&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://tqdm.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tqdm.github.io/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pinguion Stats package (comparable to scipy and statsmodel)&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://pingouin-stats.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://pingouin-stats.org/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Write an SQL query builder in 150 lines of Python!&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://death.andgravity.com/query-builder-how&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://death.andgravity.com/query-builder-how&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Science Course&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/cmparlettpelleriti/CPSC392ParlettPelleriti&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/cmparlettpelleriti/CPSC392ParlettPelleriti&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;open-source, community-driven project to help data scientists improve fairness of AI systems&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://fairlearn.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://fairlearn.org/&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Bayesian Modeling and Computation in Python&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://bayesiancomputationbook.com/welcome.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bayesiancomputationbook.com/welcome.html&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;font color=&#34;grey&#34;&gt; Originally posted: January 10, 2022&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resources: R/Stats</title>
      <link>https://iopsychist.netlify.app/post/resources-r-stats/</link>
      <pubDate>Mon, 10 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/resources-r-stats/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve gathered a number of resources which have helped me at various stages in my journey into R and Stats. By and large, the order in which they are presented reflects when I came into contact with them. All of them helped my understanding in some way. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Topic&lt;/th&gt;
&lt;th&gt;Link&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Repository of open access intro textbooks&lt;/td&gt;
&lt;td&gt;openintro.org&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Graduate Level: Intro to Probability and Statistics&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://significantstatistics.com/index.php/Graduate_Level:_Intro_to_Probability_and_Statistics&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://significantstatistics.com/index.php/Graduate_Level:_Intro_to_Probability_and_Statistics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A visual introduction to probability and statistics&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://seeing-theory.brown.edu/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://seeing-theory.brown.edu/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RShiny&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/jennybc/googlesheets/tree/master/inst/shiny-examples&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/jennybc/googlesheets/tree/master/inst/shiny-examples&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Beginners guide to RShiny&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://towardsdatascience.com/beginners-guide-to-creating-an-r-shiny-app-1664387d95b3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://towardsdatascience.com/beginners-guide-to-creating-an-r-shiny-app-1664387d95b3&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;underrated r packages&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://medium.com/@alearrigo/the-most-underrated-r-packages-254e4a6516a1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/@alearrigo/the-most-underrated-r-packages-254e4a6516a1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Modeling the 2020 elections scraping online polls in R&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://medium.com/swlh/build-a-trump-vs-biden-prediction-model-with-r-from-scratch-fa66aee9f5c2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://medium.com/swlh/build-a-trump-vs-biden-prediction-model-with-r-from-scratch-fa66aee9f5c2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Pandas gui&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/adamerose/pandasgui&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/adamerose/pandasgui&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;using Socrata / Open Data&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://hwangnyc.medium.com/using-r-to-access-311-service-request-from-nyc-open-data-using-socrata-open-data-api-and-the-83de00327a8c&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://hwangnyc.medium.com/using-r-to-access-311-service-request-from-nyc-open-data-using-socrata-open-data-api-and-the-83de00327a8c&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MIT Intro to Probability and Stats&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://ocw.aprende.org/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/Syllabus/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ocw.aprende.org/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/Syllabus/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;R for Data Science&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://r4ds.had.co.nz/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r4ds.had.co.nz/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Graphics Cookbook&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://r-graphics.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r-graphics.org/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Building Web Applications with Shiny&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://rstudio-education.github.io/shiny-course/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://rstudio-education.github.io/shiny-course/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;R/Stats/Python tutorial videos&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://statisticsglobe.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://statisticsglobe.com/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Visualizing Models and Communicating Results&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://uvastatlab.github.io/phdplus/modelviz.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://uvastatlab.github.io/phdplus/modelviz.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;data viz what color to use&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;R data scraping pt 1&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.analyticssteps.com/blogs/data-scraping-r-programming-part-1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.analyticssteps.com/blogs/data-scraping-r-programming-part-1&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Intro to Bayesian Inference&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://m.youtube.com/watch?v=o90ogqUv4AA&amp;amp;feature=youtu.be&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://m.youtube.com/watch?v=o90ogqUv4AA&amp;feature=youtu.be&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;text mining&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.tidytextmining.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.tidytextmining.com/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dataset of us cities with lat long&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/MarkMichon1/US-Cities-and-Data-COMPLETE-csv&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/MarkMichon1/US-Cities-and-Data-COMPLETE-csv&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PsycModel - R package designed for psychologists&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://jasonmoy28.github.io/psycModel/articles/quick-introduction.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://jasonmoy28.github.io/psycModel/articles/quick-introduction.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Statistics of DOOM&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=zs2qY_iRlF0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.youtube.com/watch?v=zs2qY_iRlF0&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Overview of Bootstrapping&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://statisticsbyjim.com/hypothesis-testing/bootstrapping/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://statisticsbyjim.com/hypothesis-testing/bootstrapping/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Causal Inference Textbook&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://theeffectbook.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://theeffectbook.net/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kernel Density Estimation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://mathisonian.github.io/kde/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://mathisonian.github.io/kde/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Reproducibility and the Groundhog package&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://datacolada.org/95&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://datacolada.org/95&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Statcheck R package for checking APA format papers&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://mbnuijten.com/statcheck/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://mbnuijten.com/statcheck/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Psychometrics R package&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://psychonetrics.org/r-package/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://psychonetrics.org/r-package/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;R Graph Gallery&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.r-graph-gallery.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.r-graph-gallery.com/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;EFA and CFA&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://easystats.github.io/parameters/articles/efa_cfa.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://easystats.github.io/parameters/articles/efa_cfa.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Regular Expressions helper add in&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.garrickadenbuie.com/project/regexplain/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.garrickadenbuie.com/project/regexplain/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Psychometrics in R&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://psychosystems.org/NetworkSchool&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://psychosystems.org/NetworkSchool&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fair Models - A flexible tool for bias detection, visualization, and mitigation in AI algorhithms&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://fairmodels.drwhy.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://fairmodels.drwhy.ai/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;modern dive stats textbook. NHT concepts through simulation&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://moderndive.com/9-hypothesis-testing.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://moderndive.com/9-hypothesis-testing.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Baseball analytics in R&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://tht.fangraphs.com/a-short-ish-introduction-to-using-r-for-baseball-research/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tht.fangraphs.com/a-short-ish-introduction-to-using-r-for-baseball-research/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Data Science for Social Sciences&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://datascience.tntlab.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://datascience.tntlab.org/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;TNT lab website resources for IO and R&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://rlanders.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://rlanders.net/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A tutorial on Bayesian Networks for psychopathology researchers&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://psyarxiv.com/h4vxa/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://psyarxiv.com/h4vxa/&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Fundamentals of Data Visualization&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://clauswilke.com/dataviz/aesthetic-mapping.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://clauswilke.com/dataviz/aesthetic-mapping.html&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;portfoliodown package for making portfolio website&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://www.business-science.io/code-tools/2021/12/20/portfoliodown.html?utm_content=buffer0a5e5&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.business-science.io/code-tools/2021/12/20/portfoliodown.html?utm_content=buffer0a5e5&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;R API for web app example&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/mrc-ide/hintr#readme&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/mrc-ide/hintr#readme&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;font color=&#34;grey&#34;&gt; Originally posted: January 10, 2022&lt;/font&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Talent Acquisition Process Framework</title>
      <link>https://iopsychist.netlify.app/post/talent-acquisition-process-framework/</link>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/post/talent-acquisition-process-framework/</guid>
      <description>&lt;p&gt;A good recruiter will find strong candidates. At scale, however, an organization cannot simply rely on good recruiters to fill its open positions in a reliable, time bound manner. Moreover, doing so would make it difficult to consistently plan around hiring times. With the start of 2022 seeing &lt;a href=&#34;https://twitter.com/Josh_Bersin/status/1478135382298411008&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;more job postings for Recruiters than Software Engineers&lt;/a&gt;, your organization must be strategic in its approach to hiring. Furthermore, a strong TA process will increase the effectiveness of anyone on your team seeking to support recruiting.&lt;/p&gt;
&lt;p&gt;To make Talent Acquisition a part of your organization&amp;rsquo;s strategic advantage, an effective Talent Acquisition &lt;strong&gt;&lt;em&gt;process&lt;/em&gt;&lt;/strong&gt; must be implemented. If you are facing resistance in your organization to adopting such a strategy, I lay out the business case for taking a strategic, data-driven approach.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Business Case:&lt;/strong&gt;&lt;br&gt;
Like any human process, the recruitment process for any company is&amp;ndash;at its core&amp;ndash;uncertain. The hiring team attempts to use incomplete information on the candidate&amp;rsquo;s past experience, current knowledge, dispositional traits, and future potential. The sources of this information may have varying degrees of accuracy and reliability. The candidate may exhibit different levels of performance during the interview process for reasons outside the awareness of the hiring team &amp;ndash; whether due to stress at the current job, activity in their personal life, even for such reasons of poor sleep or a
bad commute. These inconsistencies in performance are, to a larger degree than most would like to admit, unrepresentative of on-the-job-performance. Each of the guesses, estimates, and inferences that the hiring team makes during the recruiting process open the door to uncertainty, bias, and error. Not to mention, the candidate is forming judgements based on impressions from the interviewers. Even if recruitment has gone well for a position whereby the team has accurately defined their needs, sourced quality candidates, and effectively narrowed in on the strongest candidate, the candidate may not choose to ultimately join the company.&lt;/p&gt;
&lt;p&gt;The goal of a strong recruitment process is to minimize the &lt;em&gt;noise&lt;/em&gt; associated with the selection process and to maximize the likelihood that the selected candidate chooses to join the company. In the face of such uncertainty, the process itself should not add to noise in the overall system. Rather, it should open a window to the &lt;em&gt;signals&lt;/em&gt; that will allow the astute observer to understand the activity within their practices.&lt;/p&gt;
&lt;p&gt;In an organization with multiple open positions and multiple team members supporting recruiting, this means &lt;strong&gt;standardization&lt;/strong&gt; of practices. The actions of one recruiter should align with the actions of another. The milestones for one job should not differ substantially from the milestones of another. Failing to do this is costly. What happens when one recruiter gets sick, takes vacation, or leaves the organization? How does their coworker jump in and know what&amp;rsquo;s going on? If there is no understanding of metrics, how does the organization know where to put its resources? If there is no sense for time to hire, how does the team know whether they are outperforming the market or not? If new hires are not succeeding in the position, how does the company know where the function is broken in order to make changes?&lt;/p&gt;
&lt;p&gt;Adopting a framework that enables consistent processes allows for good data to be captured on all parts of the process, thus opening a window to answer these questions. You may be collecting such data already, but without this standardization what does time to hire mean, in aggregate, across your organization? Is it one day because you only add candidates into the system once they&amp;rsquo;ve completed all interviews and you want to make an offer? Is it 120 days because you sometimes don&amp;rsquo;t bother marking them as hired since you&amp;rsquo;d rather get started with their onboarding than make a quick clerical adjustment to the system? What if your ATS tells you that 65% of your hires come from LinkedIn Job Postings, your most expensive vendor, when really you haven&amp;rsquo;t captured source details for 50% of your top performing hires? Do you invest more in LinkedIn and hope to get top performers? Or do you go with you gut and invest in job fairs since you have a feeling that your best hires came through your college recruiting efforts? That&amp;rsquo;s a tough call, and it doesn&amp;rsquo;t need to be if you consistently practice good data hygiene.&lt;/p&gt;
&lt;p&gt;How does this enable success? It allows your team members to collaborate, helping each other out on the those tough to fill roles. It allows new hires to quickly get up to speed with what, exactly, your process is. It allows junior members to provide a similar candidate experience as your tenured veterans. &lt;mark&gt;Essentially, a good process &amp;lsquo;bakes in&amp;rsquo; best practices&amp;ndash;reducing onboarding times and building institutional knowledge that transcends any one team member.&lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;Once a solid TA process has been established, you can begin collecting data on what works for your organization. Stayed tuned for further posts on what this looks like and how to implement it in your position.&lt;/p&gt;
&lt;p&gt;Key Tenets:&lt;br&gt;
The key tenets of an effective TA Process are visibility and traceability. Remember, good data in &amp;ndash;&amp;gt; good data out&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example preprint / working paper</title>
      <link>https://iopsychist.netlify.app/publication/preprint/</link>
      <pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/publication/preprint/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>https://iopsychist.netlify.app/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-wowchemy&#34;&gt;Create slides in Markdown with Wowchemy&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wowchemy&lt;/a&gt; | &lt;a href=&#34;https://owchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;span class=&#34;fragment &#34; &gt;
   One 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   **Two** 
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
   Three 
&lt;/span&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/media/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/media/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wowchemy/wowchemy-hugo-modules/discussions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>https://iopsychist.netlify.app/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>https://iopsychist.netlify.app/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;
&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;
&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;
&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;
&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example journal article</title>
      <link>https://iopsychist.netlify.app/publication/journal-article/</link>
      <pubDate>Tue, 01 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/publication/journal-article/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>An example conference paper</title>
      <link>https://iopsychist.netlify.app/publication/conference-paper/</link>
      <pubDate>Mon, 01 Jul 2013 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/publication/conference-paper/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Click the &lt;em&gt;Cite&lt;/em&gt; button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    Create your slides in Markdown - click the &lt;em&gt;Slides&lt;/em&gt; button to check out the example.
  &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Supplementary notes can be added here, including &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;code, math, and images&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://iopsychist.netlify.app/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://iopsychist.netlify.app/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
