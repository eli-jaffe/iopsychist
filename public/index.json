[{"authors":null,"categories":null,"content":" Download my resum√©. -- Welcome to IOPsychist An exploration in People Analytics, Data Science, and the Future of Work ‚¨áÔ∏è Scroll for content The Purpose of IOPsychist is to inform, teach, and challenge about best practices for designing effective, efficient, and engaged environments. Here you will find articles, discussions, and guides for topics of interest to the intersection of work, psychology, and technology. This site will mainly focus on People, Talent, and Culture, but the world is wide so other content may appear from time to time. Overall, content is intended to be accessible to anyone, but some discussions may necessitate more specialized knowledge. Please, reach out on Twitter @IOPsychist with questions, comments, and ideas. Enjoy!\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://iopsychist.netlify.app/author/iopsychist/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/iopsychist/","section":"authors","summary":"Download my resum√©. -- Welcome to IOPsychist An exploration in People Analytics, Data Science, and the Future of Work ‚¨áÔ∏è Scroll for content The Purpose of IOPsychist is to inform, teach, and challenge about best practices for designing effective, efficient, and engaged environments.","tags":null,"title":"IOPsychist","type":"authors"},{"authors":null,"categories":null,"content":"   Table of Contents  What you will learn Program overview Courses in this program Meet your instructor FAQs    What you will learn  Fundamental Python programming skills Statistical concepts and how to apply them in practice Gain experience with the Scikit, including data visualization with Plotly and data wrangling with Pandas  Program overview The demand for skilled data science practitioners is rapidly growing. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi.\nCourses in this program  Python basics Build a foundation in Python.   Visualization Learn how to visualize data with Plotly.   Statistics Introduction to statistics for data science.   Meet your instructor IOPsychist FAQs Are there prerequisites? There are no prerequisites for the first course.\n How often do the courses run? Continuously, at your own pace.\n  Begin the course   ","date":1611446400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1611446400,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://iopsychist.netlify.app/courses/example/","publishdate":"2021-01-24T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"An example of using Wowchemy's Book layout for publishing online courses.","tags":null,"title":"üìä Learn Data Science","type":"book"},{"authors":null,"categories":null,"content":"Build a foundation in Python.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz What is the difference between lists and tuples? Lists\n Lists are mutable - they can be changed Slower than tuples Syntax: a_list = [1, 2.0, \u0026#39;Hello world\u0026#39;]  Tuples\n Tuples are immutable - they can‚Äôt be changed Tuples are faster than lists Syntax: a_tuple = (1, 2.0, \u0026#39;Hello world\u0026#39;)   Is Python case-sensitive? Yes\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"17a31b92253d299002593b7491eedeea","permalink":"https://iopsychist.netlify.app/courses/example/python/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/python/","section":"courses","summary":"Build a foundation in Python.\n","tags":null,"title":"Python basics","type":"book"},{"authors":null,"categories":null,"content":"Learn how to visualize data with Plotly.\n  1-2 hours per week, for 8 weeks\nLearn   Quiz When is a heatmap useful? Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n Write Plotly code to render a bar chart import plotly.express as px data_canada = px.data.gapminder().query(\u0026#34;country == \u0026#39;Canada\u0026#39;\u0026#34;) fig = px.bar(data_canada, x=\u0026#39;year\u0026#39;, y=\u0026#39;pop\u0026#39;) fig.show()  ","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"1b341b3479c8c6b1f807553b77e21b7c","permalink":"https://iopsychist.netlify.app/courses/example/visualization/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/visualization/","section":"courses","summary":"Learn how to visualize data with Plotly.\n","tags":null,"title":"Visualization","type":"book"},{"authors":null,"categories":null,"content":"Introduction to statistics for data science.\n  1-2 hours per week, for 8 weeks\nLearn The general form of the normal probability density function is:\n$$ f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi} } e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $$\n The parameter $\\mu$ is the mean or expectation of the distribution. $\\sigma$ is its standard deviation. The variance of the distribution is $\\sigma^{2}$.   Quiz What is the parameter $\\mu$? The parameter $\\mu$ is the mean or expectation of the distribution.\n","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"6f4078728d71b1b791d39f218bf2bdb1","permalink":"https://iopsychist.netlify.app/courses/example/stats/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/courses/example/stats/","section":"courses","summary":"Introduction to statistics for data science.\n","tags":null,"title":"Statistics","type":"book"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy‚Äôs Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://iopsychist.netlify.app/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":["Showcase","Code","Python","LLM"],"content":"Harnessing the Power of Generative AI in I/O Psychology: Insights from the SIOP 2024 Machine Learning Competition I recently had the exhilarating opportunity to participate in the SIOP 2024 Machine Learning Competition, a pioneering event sponsored by HackerRank, DDI, and the Department of Psychology at Virginia Tech. This competition was a playground for showcasing the synergy between Large Language Models (LLMs) and Industrial/Organizational (I/O) Psychology, aiming to explore the potentials and boundaries of AI in our field.\nThe Challenge and My Journey The competition posed four intriguing challenges, each designed to reflect common tasks in I/O Psychology:\n Predicting Empathy in Workplace Responses Generating Interview Responses Rating Item Clarity for Personality Tests Identifying Fairness Perceptions in Organizational Policies  Using a quantized Mixtral model (a mixture of experts), I ventured into these tasks with a mix of curiosity and technical acumen. My approach involved crafting Python scripts in a Google Colab notebook, meticulously tuning the model to resonate with the intricacies of I/O psychology-related queries.\nSurpassing Expectations with LLMs The journey was not just about solving problems but also about discovering the remarkable capabilities of LLMs in understanding and predicting human behavior and organizational phenomena. To my delight, the accuracy of my solutions surpassed expectations, underscoring the robustness and adaptability of LLMs in handling nuanced psychological data.\nWhy People Analytics and I/O Psychology Should Embrace Generative AI My experiences during the competition solidified my belief that People Analytics professionals and I/O Psychologists are uniquely positioned to leverage Generative AI. Our foundational skills in analyzing human behavior and organizational dynamics align seamlessly with the capabilities of LLMs, allowing us to extract meaningful insights and foster innovation in our practices.\nSharing the Knowledge In the spirit of collaboration and knowledge-sharing, I have made my code available on GitHub. This repository not only contains the scripts used in the competition but also serves as a resource for those interested in integrating Generative AI into their I/O Psychology workflows.\nCheck out my GitHub repository for the competition code\nIn conclusion, the SIOP 2024 Machine Learning Competition was not just a contest but a learning journey that highlighted the symbiotic relationship between I/O Psychology and Generative AI. As we move forward, embracing these advanced technologies will undoubtedly lead to more innovative, efficient, and effective outcomes in our field.\n","date":1712793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712793600,"objectID":"14a121f26c390b695d55568abe96fbf5","permalink":"https://iopsychist.netlify.app/post/siop-ml-competition-2024/","publishdate":"2024-04-11T00:00:00Z","relpermalink":"/post/siop-ml-competition-2024/","section":"post","summary":"Harnessing the Power of Generative AI in I/O Psychology: Insights from the SIOP 2024 Machine Learning Competition I recently had the exhilarating opportunity to participate in the SIOP 2024 Machine Learning Competition, a pioneering event sponsored by HackerRank, DDI, and the Department of Psychology at Virginia Tech.","tags":null,"title":"SIOP ML Competition 2024 - LLMs","type":"post"},{"authors":[],"categories":["World of Work","People Analytics"],"content":"  The 11th Annual Conference on Human Capital Innovation in Technology \u0026amp; Analytics \nIn April, I had my first opportunity to present at an academic conference - the 11th Annual Conference on Human Capital Innovation in Technology and Analytics at NYU. This year‚Äôs topic was ‚ÄúThe Great Resignation: How Analytics Can Help‚Äù. I spoke about some of the work I‚Äôve been involved in with Frank Mo and the Human Capital Analytics Lab to forecast job demand in the Knowledge Worker and Service Worker industries. I learned quite a bit through the process of preparing for, presenting, and discussing our work. It was very cool to hear what the other presenters were working on in their companies and research institutes as well. Also among the speakers were team members from the Conference Board, Accenture, Microsoft, and Johnson \u0026amp; Johnson - quite a lineup to follow!\nIn our research, we worked with data from Candogram - an awesome company that provides job market education to students and, in doing so, processes 2 million job ads per day from 10,000 US employers - and from the BLS Job Openings and Labor Turnover survey (JOLTS). Our central research question looked at the spike in voluntary quits during the Great Resignation as a precipitating event for changes in labor market demand. To uncover insight into this, we tested two advanced time series forecasting methods - Facebook‚Äôs Prophet model and LinkedIn‚Äôs Silverkite model. It turns out there is a relationship between job quits and job demand, but it depends on which industry you‚Äôre looking at!\nWe are currently working on a white paper which we hope to release in the next few weeks but you can get a sneak peak into what we found from the slide deck from our presentation. This is just the start and there are many future directions we are considering. In the meantime, we‚Äôd love to hear your thoughts and feedback! Stay tuned for further updates coming soon.\n\nOriginally posted: July 11, 2022\n ","date":1657497600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657548832,"objectID":"8112913ef9b78d89a20d021c72adbf96","permalink":"https://iopsychist.netlify.app/post/recap-the-11th-annual-conference-on-human-capital-innovation-in-technology-analytics/","publishdate":"2022-07-11T00:00:00Z","relpermalink":"/post/recap-the-11th-annual-conference-on-human-capital-innovation-in-technology-analytics/","section":"post","summary":"The 11th Annual Conference on Human Capital Innovation in Technology \u0026 Analytics \nIn April, I had my first opportunity to present at an academic conference - the 11th Annual Conference on Human Capital Innovation in Technology and Analytics at NYU.","tags":["future of work","research","labor market","blog","time series"],"title":"I presented at The 11th Annual Conference on Human Capital Innovation in Technology \u0026 Analytics (slides attached)","type":"post"},{"authors":[],"categories":["People Analytics"],"content":"  I recently supported an organization with running their annual engagement survey. The survey was divided into six sections, focusing on themes such as ‚ÄòMy Job‚Äô, ‚ÄòTrust in Leadership‚Äô, and ‚ÄòCompensation and Benefits‚Äô. A section of particular interest to the head of HR was the ‚ÄòMy Manager‚Äô section. In this section, employees responded to 13 questions on a 5 point scale:\n My manager communicates clear goals for our team. My manager ensures that I am well-informed about issues that affect my work. My manager supports my professional growth and development. My manager has had a meaningful discussion with me about my career development in the past six months. My manager gives actionable feedback on a regular basis. My manager provides the autonomy I need to do my job. The actions of my manager show they value the perspective I bring to the team, even if it is different from their own. My manager does a good job in focusing our team on the most important work My manager does an effective job at helping me and my teammates adapt to changes affecting our department. My manager effectively collaborates across departments. I would consider my manager to be an effective decision maker. My manager holds the team accountable for demonstrating [Company]‚Äôs values while driving results.  Response options were ‚ÄòStrongly Disagree‚Äô, ‚ÄòDisagree‚Äô, ‚ÄòNeutral‚Äô, ‚ÄòAgree‚Äô, and ‚ÄòStrongly Agree‚Äô\nWith survey data, especially in industry, it is often helpful to understand the response distributions to each questions. Luckily, the R package ggridges can help us do so quickly and easily.\nSince the actual data is confidential, I will simulate a response pattern and show how item distributions can be visualized using ggplot and ggridges.\n# import required packages library(readxl) library(dplyr) library(stringr) library(tidyr) library(ggplot2) library(ggridges) Simulate Data To start, let‚Äôs create a dataset of 100 ‚Äòtrue‚Äô levels of the underlying trait we are interested in measuring.\nset.seed(1359) N = 100 # let\u0026#39;s say we had 100 respondents # each respondent has a \u0026#39;true\u0026#39; score on the latent variable we are measuring # let\u0026#39;s model that here, assuming a normal distribution latent = rnorm(N, mean = 0, sd = 1) # each measurement will have a slight error on top of the true score # define that error for each of the 13 items we will generate sds \u0026lt;- runif(n=13, min=0, max=1.5) # initialize our items and vals list items = c() vals \u0026lt;- list() # create item responses for each 13 items for (i in seq(length(sds))) { items \u0026lt;- append(items, paste0(\u0026#39;item\u0026#39;, i)) scores \u0026lt;- latent + rnorm(N, mean=0, sd=sds[i]) vals[i] \u0026lt;- list(scores) } # name the list and cast to dataframe names(vals) \u0026lt;- items dat \u0026lt;- as.data.frame(vals) # we now have a dataframe of each employee\u0026#39;s score on each item We now have the data of each employee‚Äôs true score on the measure.\nWhile each employee has a ‚Äòtrue‚Äô level on the latent variable, in reality they also have a ‚Äòresponse‚Äô level they would indicate based on the question design. For example, Sam is experiencing moderate-high levels of burnout - their true burnout level is 7 out of 10. Sam reads a survey question aimed at identifying burnout: ‚ÄúI feel burnout out from the demands of my job‚Äù with 5 response options ranging from Strongly Disagree to Agree. Sam selects ‚ÄòAgree‚Äô. Another employee, Jordan, is not as burned out - their true level is a 5 out of 10. Jordan reads the same question and thinks, ‚Äúwell, I do feel burnout from the demands of my job. It‚Äôs mostly manageable but I still agree with the statement, so I will indicate ‚ÄòAgree‚Äô‚Äù. Both Sam and Jordan responded to the item with the same response, even though their ‚Äòtrue‚Äô score, the level of burnout they are experiencing, is different.\nWe can model this interaction by defining interval buckets to categorize how an employee would respond based on their true score. For now, we will assume all items are positively scored (i.e the higher the response score, the higher the underlying True score). In most companies that use survey questions measured on the scale described previously, the majority of employees will select ‚ÄòAgree‚Äô or ‚ÄòStrongly Agree‚Äô. Those that do not will tend to select the neutral option, and the very few employees remaining will indicate some level of disagreement. Therefore, we will define our response intervals as follows:\n if an employee‚Äôs true score is very very low (2.5 or more standard deviations below the mean),they will respond with ‚ÄòStrongly Disagree‚Äô. For those employees 2.5-2 deviations below the mean, they will select ‚ÄòDisagree‚Äô Employees who are 2 to -0.5 deviations below the mean indicate ‚ÄòNeutral‚Äô Employees 0.5 below the mean to 1 deviation above will select ‚ÄòAgree‚Äô. The rest will select ‚ÄòStrongly Agree‚Äô  We can define these interval breakpoints in a list c(-Inf, -2.5, -2, -.5, 1, Inf)\n##### generate latent responses to items # apply findInterval function to convert latent scores to ordered categories dat \u0026lt;- dat |\u0026gt; mutate(across(starts_with(\u0026#39;item\u0026#39;), ~ ‚Ä¶","date":1656979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657031741,"objectID":"9a506575a3bd88ea5d729a07620bd1ca","permalink":"https://iopsychist.netlify.app/post/visualizing-survey-response-distributions/","publishdate":"2022-07-05T00:00:00Z","relpermalink":"/post/visualizing-survey-response-distributions/","section":"post","summary":"I recently supported an organization with running their annual engagement survey. The survey was divided into six sections, focusing on themes such as ‚ÄòMy Job‚Äô, ‚ÄòTrust in Leadership‚Äô, and ‚ÄòCompensation and Benefits‚Äô.","tags":["R","surveys","tutorial"],"title":"Visualizing Survey Response Distributions","type":"post"},{"authors":[],"categories":["People Analytics"],"content":"  Coming Soon  Overview This is part 2 of the Pay Equity Analysis. In part 1, we gathered the dataset we will be using which contains pay information on City of Philadelphia employees. In part 2 we will conduct the actual pay equity analysis. The goal is to present an example of how a pay equity analysis may be conducted that can be used in your organization. The tutorial consists of two main phases:\nData Collection and Cleaning   This step uses Python for scraping the data from the web and collecting it into a workable file for analysis. We use a basic method to impute gender identification to give us a more real world example (note: this also limits the accuracy of our analysis. These results should not be interpreted to be an actual representation of pay equity among City of Philadelphia employees). Likely you will have direct access to the necessary data through your organization and this step will be unnecessary. Feel free to skip to the next section if so. However, if you are looking for a working data set to practice on your own, this section may be helpful.  Pay Equity Analysis   This is likely where you will start within your organization. I walk through two methods for analyzing pay data ‚Äì Regression as well as Classification and Regression Tree (CART) modeling. The analysis has been conducted using R.  # Setup #load packages library(tidyverse) ## ‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.1 ‚îÄ‚îÄ ## ‚úì ggplot2 3.3.5 ‚úì purrr 0.3.4 ## ‚úì tibble 3.1.6 ‚úì dplyr 1.0.8 ## ‚úì tidyr 1.1.3 ‚úì stringr 1.4.0 ## ‚úì readr 1.4.0 ‚úì forcats 0.5.1 ## Warning: package \u0026#39;dplyr\u0026#39; was built under R version 4.1.2 ## ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() # read in the data mydata \u0026lt;- read_csv(\u0026#39;MVR_preprocessed_data.csv\u0026#39;) ## Warning: Missing column names filled in: \u0026#39;X1\u0026#39; [1] ## ## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ## cols( ## X1 = col_double(), ## last_name = col_character(), ## first_name = col_character(), ## title = col_character(), ## job_code = col_character(), ## department_name = col_character(), ## department_number = col_double(), ## base_salary = col_double(), ## likely_male = col_double(), ## likely_female = col_double(), ## jobClassCode = col_character(), ## jobClassTitle = col_character(), ## payRange = col_character(), ## jobClassSalaryMin = col_double(), ## jobClassSalaryMax = col_double(), ## unionCode = col_character(), ## flsaCode = col_character(), ## effectiveDate = col_date(format = \u0026#34;\u0026#34;), ## family = col_double() ## ) \nOriginally posted: January 18, 2022\n ","date":1645315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645392680,"objectID":"aa8df2f6078d903c8ae31b6a4cc1c4c1","permalink":"https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-2/","publishdate":"2022-02-20T00:00:00Z","relpermalink":"/post/tutorial-pay-equity-analysis-part-2/","section":"post","summary":"Coming Soon  Overview This is part 2 of the Pay Equity Analysis. In part 1, we gathered the dataset we will be using which contains pay information on City of Philadelphia employees.","tags":["R","Python","Compensation","DEI","tutorial"],"title":"Tutorial: Pay Equity Analysis [Part 2]","type":"post"},{"authors":[],"categories":["Culture"],"content":"\nA recent SHRM survey found that during the tight labor market spurred by the Covid-19 pandemic, companies ‚Äústepped up their use of sign-on, referral, spot and retention bonuses to attract and keep employees.‚Äù One company found that job ads ‚Äúoffering a sign-on bonus have increased across all sectors by a whopping 454%, from 10,312 positions in August 2020 to 57,123 in August 2021.‚Äù These types of rewards, also called incidental rewards, have been used to effectively increase employee earnings during the pandemic.\n div.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}  SHRM survey fast facts:  52 percent of respondents increased the number of sign-on bonuses awarded in the past 12 months. 49 percent have increased the number of retention bonuses awarded   Prior to the pandemic, real wage growth in the US was relatively stagnant despite hot job markets and a substantial increase in productivity. This discrepancy disproportionately affected lower income brackets, contributing to further inequality in earnings. These low-skilled jobs often form a company‚Äôs front-line workforce - a.k.a. those with the highest risk of infection during a pandemic. Covid-19 forced a lot of companies to recognize the importance of these employees to their operating models. It is quicker and easier to provide one-time bonuses or extra-salary compensation than adjust the entire compensation framework for a company. As a policy, it is also easier to unwind post pandemic. Together with increased competition for labor, this was a quick way for companies to respond as the tight market dynamics arose.\nHowever, rewards based on participation or engagement (as opposed to performance-based rewards) are perhaps the most detrimental type of reward to internal motivation. Why is this important? While the difference between a wage increase and a bonus may be important to employers, the total earnings are more salient to employees than the method by which they were received. Given that we‚Äôve now been operating in ‚Äòpandemic-mode‚Äô for over 20 months, employees may come to expect the total package they are receiving. Furthermore, these bonuses provide extrinsic motivation which works to shift workers\u0026#39; motivation away from any intrinsic sources they have conceived of previously. All else being equal, it is harder to shift from extrinsic to intrinsic motivation. When these external rewards dry up, companies will face challenges in motivating their employees.\nFrom an I/O perspective, employee motivation should be an important consideration when deciding how to maneuver. This awareness may not make it into the room where compensation and bonus decisions are being made. Viewed purely from a financial lens it may seem attractive to roll back variable pay. However, rolling back expected earnings may hurt employee motivation, thereby decreasing productivity. This loss in output per employee may incur more overall costs to the company in the form of presenteeism, loss of organizational citizenship behavior, and increased hiring costs. Whether these externalities cost the company more than the compensation savings is a question each employer will have to answer for themselves. Regardless, unwinding pandemic-era cash incentives will be a line that employers must navigate as they carve a path forward, and is not as simple as simply returning to the way things were pre-Covid.\nOriginally posted: February 2, 2022","date":1643760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643814436,"objectID":"e57363c62d96b498379754bbdfb1d3f8","permalink":"https://iopsychist.netlify.app/post/the-impact-of-sign-on-and-retention-bonuses-on-extrinsic-motivation/","publishdate":"2022-02-02T00:00:00Z","relpermalink":"/post/the-impact-of-sign-on-and-retention-bonuses-on-extrinsic-motivation/","section":"post","summary":"A recent SHRM survey found that during the tight labor market spurred by the Covid-19 pandemic, companies ‚Äústepped up their use of sign-on, referral, spot and retention bonuses to attract and keep employees.","tags":["motivation","rewards","incentives","future of work"],"title":"The Impact of Sign-on and Retention Bonuses on Extrinsic Motivation","type":"post"},{"authors":[],"categories":["People Analytics"],"content":"  Overview In this tutorial, we will conduct a pay equity analysis on publicly available pay information for the City of Philadelphia. The goal is to present an example of how a pay equity analysis may be conducted that can be used in your organization. The tutorial consists of two main phases:\nData Collection and Cleaning   This step uses Python for scraping the data from the web and collecting it into a workable file for analysis. We use a basic method to impute gender identification to give us a more real world example (note: this also limits the accuracy of our analysis. These results should not be interpreted to be an actual representation of pay equity among City of Philadelphia employees). Likely you will have direct access to the necessary data through your organization and this step will be unnecessary. Feel free to skip to the next section if so. However, if you are looking for a working data set to practice on your own, this section may be helpful.  Pay Equity Analysis   This is likely where you will start within your organization. I walk through two methods for analyzing pay data ‚Äì Regression as well as Classification and Regression Tree (CART) modeling. The analysis has been conducted using R.   Part 1 - Data Collecetion and Cleaning Employee Salary The City of Philadelphia participates in an Open Data program where they publish many different data sets related to the Philadelphia region, including information on pay for public employees. Using this resource, we can pull in the bulk of the data necessary to conduct a pay equity analysis. To begin with, let‚Äôs import the necessary Python packages we will need. On top of the typical data science tools (pandas, numpy, seaborn, etc), we will be using requests for our API calls, json for parsing the data we get back, and BeautifulSoup for web scraping. There are a few auxiliary packages as well‚Äìgo ahead and load them all so that everything works as intended.\nimport pandas as pd import matplotlib.pyplot as plt import numpy as np import seaborn as sns sns.set() import requests import json import ast from bs4 import BeautifulSoup from datetime import datetime On the OpenDataPhilly.org website we can find Employee Earnings data by quarter, which has be provided with API access for us to use. We start by defining the URL to access the data. If you look at the URL, you will see the raw JSON. The requests package gets this JSON data and we next parse the JSON into the variable data.\nURL = \u0026#39;https://phl.carto.com/api/v2/sql?q=SELECT%20*%20FROM%20employee_earnings\u0026#39; page = requests.get(URL) j_data = page.content data = json.loads(j_data) Let‚Äôs look at the variable data.\n# let\u0026#39;s look at the variable data type(data) # we see that is a dict # looking at the keys, we see there are \u0026#39;rows\u0026#39;, \u0026#39;time\u0026#39;, \u0026#39;fields\u0026#39;, and \u0026#39;total_rows\u0026#39; ## \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; data.keys() ## dict_keys([\u0026#39;rows\u0026#39;, \u0026#39;time\u0026#39;, \u0026#39;fields\u0026#39;, \u0026#39;total_rows\u0026#39;]) We see that is of type dict with the keys ‚Äòrows‚Äô, ‚Äòtime‚Äô, ‚Äòfields‚Äô, and ‚Äòtotal_rows‚Äô. Rows seems relevant to our needs, and we can confirm this by looking at a single observation.\n# rows seem like what we\u0026#39;ll need print(data[\u0026#39;rows\u0026#39;][0]) ## {\u0026#39;cartodb_id\u0026#39;: 1, \u0026#39;the_geom\u0026#39;: None, \u0026#39;the_geom_webmercator\u0026#39;: None, \u0026#39;calendar_year\u0026#39;: 2021, \u0026#39;quarter\u0026#39;: 3, \u0026#39;last_name\u0026#39;: \u0026#39;Manko Jr\u0026#39;, \u0026#39;first_name\u0026#39;: \u0026#39;Theodore\u0026#39;, \u0026#39;title\u0026#39;: \u0026#39;Detective\u0026#39;, \u0026#39;job_code\u0026#39;: \u0026#39;6A12\u0026#39;, \u0026#39;department_name\u0026#39;: \u0026#39;PPD Police\u0026#39;, \u0026#39;department_number\u0026#39;: \u0026#39;11\u0026#39;, \u0026#39;base_salary\u0026#39;: 85901, \u0026#39;salary_type\u0026#39;: \u0026#39;Salaried\u0026#39;, \u0026#39;overtime_gross_pay_qtd\u0026#39;: 1110.82, \u0026#39;base_gross_pay_qtd\u0026#39;: 23039.1, \u0026#39;longevity_gross_pay_qtd\u0026#39;: 2096.58, \u0026#39;post_separation_gross_pay_qtd\u0026#39;: None, \u0026#39;miscellaneous_gross_pay_qtd\u0026#39;: 7782.08, \u0026#39;employee_category\u0026#39;: \u0026#39;Civil Service\u0026#39;, \u0026#39;compulsory_union_code\u0026#39;: \u0026#39;P\u0026#39;, \u0026#39;termination_month\u0026#39;: None, \u0026#39;termination_year\u0026#39;: None, \u0026#39;public_id\u0026#39;: 5610} # pull this into a pandas dataframe df = pd.DataFrame(data[\u0026#39;rows\u0026#39;]) df.head() ## cartodb_id the_geom ... termination_year public_id ## 0 1 None ... NaN 5610 ## 1 2 None ... NaN 319 ## 2 3 None ... NaN 21446 ## 3 4 None ... NaN 29891 ## 4 5 None ... 2021.0 14611 ## ## [5 rows x 23 columns] Great, we now have the beginning of our data set. Let‚Äôs take a look at what we have.\n# we have 23 columns and over 316,000 observations df.info() ## \u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt; ## RangeIndex: 316304 entries, 0 to 316303 ## Data columns (total 23 columns): ## # Column Non-Null Count Dtype ## --- ------ -------------- ----- ## 0 cartodb_id 316304 non-null int64 ## 1 the_geom 0 non-null object ## 2 the_geom_webmercator 0 non-null object ## 3 calendar_year 316304 non-null int64 ## 4 quarter 316304 non-null int64 ## 5 last_name 316304 non-null object ## 6 first_name 316304 non-null object ## 7 title 316304 non-null object ## 8 job_code 316304 non-null object ## 9 department_name 316304 non-null object ## 10 department_number 316304 non-null object ## 11 base_salary 300770 non-null float64 ## 12 salary_type 316303 non-null object ## 13 overtime_gross_pay_qtd 164753 non-null float64 ## 14 base_gross_pay_qtd 316304 non-null ‚Ä¶","date":1642377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642563114,"objectID":"7fe672ef4aaabdc6669fb30afcf29f52","permalink":"https://iopsychist.netlify.app/post/tutorial-pay-equity-analysis-part-1/","publishdate":"2022-01-17T00:00:00Z","relpermalink":"/post/tutorial-pay-equity-analysis-part-1/","section":"post","summary":"Overview In this tutorial, we will conduct a pay equity analysis on publicly available pay information for the City of Philadelphia. The goal is to present an example of how a pay equity analysis may be conducted that can be used in your organization.","tags":["Python","R","Compensation","DEI","tutorial"],"title":"Tutorial: Pay Equity Analysis [Part 1]","type":"post"},{"authors":[],"categories":["World of Work"],"content":"While I am a few days late on this 2022 prediction, this blog was only an idea 10 days ago so please be generous. Truth be had, however, I first wrote this prediction (albeit privately) on 12/24/21, clearly ahead of the New Year‚Äôs Eve deadline. So, what do I predict? In 2022, we are going to see average salaries rise in non-peak markets in the United States due to remote friendly jobs.\nWhen the pandemic first began, cities like San Francisco and New York saw an exodus. Employees with newfound flexibility realized that the city was no longer fun during lockdown, so why not be somewhere with more space and more things to do at a percentage of the cost? Initially, companies still holding to the traditional ways of thinking announced that location-based wage adjustments would be conducted for those who decided to move away from the cities permanently. Almost as soon, however, other companies realized that not cutting wages for remote workers could form a competitive advantage in the competition for talent. Reddit, for example, eliminated geographic compensation zones in the US. Overall, however, the wisdom of the crowds still thought that pay would decrease for workers who moved away from the city.\nFast forward to the beginning of 2022, almost 2 years into the pandemic. The return to the office was not a quick as we thought with the Delta and now Omicron waves halting our progress back to carefree in-person activities. The ‚ÄòGreat Resignation‚Äô seen in 2021 is now being seen more accurately as the ‚ÄòGreat Reshuffle‚Äô. In November, job openings surpassed total separations (which not only includes employees who quit, but also those who were fired, laid off, or otherwise separated from their employer) by almost 1.7X. Despite largely being remote for the better part of 2 years, many companies are seeing higher revenues than before the pandemic. Instead of hindering efficiency, remote work has so far stood the test and companies seeing a need to hire are now feeling pressure to fill openings in a candidate‚Äôs market.\nAmericans are moving out of big, expensive cities into more affordable locations. This movement however, isn‚Äôt changing the talent pool in the same way it would have before the pandemic. Employers looking for any edge they can get in the struggle to attract talent are looking further afield than pre-pandemic as well (i.e remote). According to PayScale‚Äôs 2021 State of Remote Work Report, employees who work remotely don‚Äôt earn less compensation. For companies that are a) seeing higher revenues and b) looking to attract top talent, the calculations will result in a simple solution ‚Äì continue to pay to the highest geo-location they operate in. This means that companies in New York or the Bay Area will offer the same salary to remote employees as they offer to in-person or hybrid employees. Top talent in any market will be attracted to the salaries offered by these companies, forcing smaller companies and those not located to peak cities to compete with peak city wages, whether they like it or not.\n2022 will (hopefully) see the end of the pandemic, however some things will never go back to the way they were. Expect to see wages rises in secondary and tertiary locations as the effects of the great reshuffle continue to ripple through the world of work.\nOriginally posted: January 11, 2022","date":1641859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641909373,"objectID":"82ba94d3913d32a347dc9d6e2425a7f7","permalink":"https://iopsychist.netlify.app/post/remote-work-salary-trends/","publishdate":"2022-01-11T00:00:00Z","relpermalink":"/post/remote-work-salary-trends/","section":"post","summary":"While I am a few days late on this 2022 prediction, this blog was only an idea 10 days ago so please be generous. Truth be had, however, I first wrote this prediction (albeit privately) on 12/24/21, clearly ahead of the New Year‚Äôs Eve deadline.","tags":[],"title":"Why Remote Work Won't Lead to Lower Salaries","type":"post"},{"authors":[],"categories":["People Analytics"],"content":"Sometimes, the database you want to connect a Jupyter Notebook to is located behind an SSH tunnel. Using the files here, you can set establish the SSH connection and connect to the database all from within Python.\nI have this set up such that both the config file and the connector methods are separate from the Python script you are working in. However, you can also copy the mypython_dbconnector.py file into a Jupyter Notebook and not worry about importing it. I like the separation to keep the ipynb file clean. Note: this code is adapted from https://practicaldatascience.co.uk/data-science/how-to-connect-to-mysql-via-an-ssh-tunnel-in-python\nCreate the functions we will use We need to define a few functions for easily connecting to the database. In this case, we are connecting to a MySQL database so we use the Python package pymysql. This can easily be changed to a different database if your needs require.\nCreate a file mypython_dbconnector.py with the following code:\nimport pandas as pd import matplotlib.pyplot as plt import pymysql import logging import sshtunnel from sshtunnel import SSHTunnelForwarder import config # define the functions we will be using def open_ssh_tunnel(verbose=False): \u0026#34;\u0026#34;\u0026#34;Open an SSH tunnel and connect using a username and password. :param verbose: Set to True to show logging :return tunnel: Global SSH tunnel connection \u0026#34;\u0026#34;\u0026#34; if verbose: sshtunnel.DEFAULT_LOGLEVEL = logging.DEBUG global tunnel tunnel = SSHTunnelForwarder( (config.ssh_host, 22), ssh_username = config.ssh_username, ssh_password = config.ssh_password, remote_bind_address = (\u0026#39;127.0.0.1\u0026#39;, 3306) ) tunnel.start() def mysql_connect(): \u0026#34;\u0026#34;\u0026#34;Connect to a MySQL server using the SSH tunnel connection :return connection: Global MySQL database connection \u0026#34;\u0026#34;\u0026#34; global connection connection = pymysql.connect( host=\u0026#39;127.0.0.1\u0026#39;, user=config.database_username, password=config.database_password, database=config.database_name, port=tunnel.local_bind_port ) def run_query(sql): \u0026#34;\u0026#34;\u0026#34;Runs a given SQL query via the global database connection. :param sql: MySQL query :return: Pandas dataframe containing results \u0026#34;\u0026#34;\u0026#34; return pd.read_sql_query(sql, connection) def mysql_disconnect(): \u0026#34;\u0026#34;\u0026#34;Closes the MySQL database connection. \u0026#34;\u0026#34;\u0026#34; connection.close() def close_ssh_tunnel(): \u0026#34;\u0026#34;\u0026#34;Closes the SSH tunnel connection. \u0026#34;\u0026#34;\u0026#34; tunnel.close  Note: saving this file as dbconnector.py may interfere with other packages in your environment and lead to unexpected behaviors.  Create the config file with our connection credentials Next, we need to provide python with the credentials to connect. I like to define these in a separate file so that I can share the actual Jupyter notebook with my work and not have to worry about security. Enter your usernames and passwords in the file below and save it as config.py.\n# Standard TCP/IP # may need to change this depending on your tunnel connection details ssh_host = \u0026#39;128.122.34.205\u0026#39; # port 22 by default ssh_username = \u0026#39;SSH_USERNAME\u0026#39; ssh_password = \u0026#39;SSH_PASSWORD\u0026#39; database_name = \u0026#39;YOUR_DATABASE_NAME\u0026#39; localhost = \u0026#39;127.0.0.1\u0026#39; # port 3306 by default database_username = \u0026#39;YOUR_USERNAME\u0026#39; database_password = \u0026#39;YOUR_PASSWORD\u0026#39;  Connect to the database and get to work! Finally, we are ready to connect and start working with our data. Make sure both the files we just created are in the same directory and then create a new Jupyter Notebook file in the same location.\nimport pandas as pd import matplotlib.pyplot as plt import numpy as np import mypython_dbconnector  We start with the imports we will be using for our work, along with importing our file mypthon_dbconnector.py. Now, all we need to do is call the functions we defined earlier. We then pass our sql query as a string to our run_query() command and save the return value to a dataframe. Rinse and repeat as necessary!\n# connect to ssh tunnel and to mysql db mypython_dbconnector.open_ssh_tunnel() mypython_dbconnector.mysql_connect() # define query query = \u0026#39;\u0026#39;\u0026#39; SELECT * FROM table_name \u0026#39;\u0026#39;\u0026#39; df = mypython_dbconnector.run_query(query) # your data analysis here # TODO # close mysql connection and close ssh tunnel mypython_dbconnector.mysql_disconnect() mypython_dbconnector.close_ssh_tunnel()  Once you are connected to the database through the ssh tunnel, you can access it a you normally would. Be sure to disconnect from the database and close the SSH tunnel when you are done working with it. The full directory setup with example jupyter notebook can be found at https://github.com/eli-jaffe/ssh_mysql_connect.\n","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641824371,"objectID":"c5161f3d49712ed4f53493597e509685","permalink":"https://iopsychist.netlify.app/post/configuring-an-ssh-connection-in-jupyter-notebooks/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/post/configuring-an-ssh-connection-in-jupyter-notebooks/","section":"post","summary":"Sometimes, the database you want to connect a Jupyter Notebook to is located behind an SSH tunnel. Using the files here, you can set establish the SSH connection and connect to the database all from within Python.","tags":["Jupyter","Python","Database","MySQL","tutorial"],"title":"Configuring an SSH connection in Jupyter Notebooks","type":"post"},{"authors":[],"categories":["Talent Acquisition"],"content":"When a new position is opened, the hiring manager should be able to express the why, the what, the when, and the where behind the position. This includes the reason the position is being requested, what the position will be responsible for and what projects the incumbent will likely be part of, when the position will be needed and the hours per week the position will require, and where the position will need to be located, among other relevant details to the position.\nBeing able to explain these aspects up front is important for a few reasons. It ensures the position (and, therefore, the need for the position) has been carefully considered and determined to be appropriate. The recruitment process requires significant time, energy, and money from the hiring team, the recruiting team, and candidates. If there is not a clear reason for the position, it should be reconsidered whether the role is necessary at the current time. Furthermore, hiring and onboarding a new employee requires time, resources, and has potential long-term impact for the company ‚Äì good or bad. While it may be tempting to bring on additional help as needed, answering these questions up front will ensure that the benefits and costs are appropriately weighed.\nTactically, being able to communicate these questions at the beginning of the process to the recruiting team will greatly improve the efficiency and effectiveness of the recruiting process. With a clear understanding of the need to have and nice to have aspects of the position, as well as the fit within the organization, the recruiting team is able to more accurately source and evaluate candidates.\nThink of the hiring process like searching for a car to buy. You (the hiring manager) may know you want a good commuter car that can hold your family comfortably. This would be equivalent to knowing the job title of the opening. If you were to ask someone to find you the right car for your needs, there would be quite a range of options for them to select ‚Äì likely some which you‚Äôre not interested in. Furthermore, once you‚Äôve narrowed your search down to a specific make/model (say, after you‚Äôve reviewed a few ‚Äòcandidate cars‚Äô or done further research), there are still more details that are important. Do you want new or used? What color interior or exterior? Do you want to spring for some of the enhanced features? All of them? None of them? So, while you started with what may be thought of as a well-defined need (i.e. commuter car that can hold your family), we see that there are actually numerous other details to consider. Imagine if you provided preferences on the color, new vs used, perhaps even the make and model up front. There would still be details to choose between of course (based on what‚Äôs available on the market in your area at the time of your search) but you would have sped up the selection process considerably, possibly giving you access to cars available on the market that you might have been too late for with the previous approach. Now, imagine that you are searching for 50 cars a year, and you are losing money each day that the search lasts. This is why detailed requests up front are important.\nTo facilitate this, when a new position is opened, the recruiter (or coordinator) responsible for working on the position should have an intake discussion with the hiring manager. Using the example intake form below, they will be able to review the position details and align on the needs of the hiring manager. While not all the possible questions may be answerable up front, and while things may change over the course of the recruiting process, the team should aim as much as possible for accuracy and completeness of these answers. Also, keep in mind that the recruiter will need to be able to describe the opening to candidates and build up excitement for the opportunity. Completing the intake will save the company money, enhance the quality of candidates and hires, and increase the velocity of hiring.\nExample New Job Intake Form  Role and Responsibilities\nWhat will this person be doing?\nNeed to haves?\nNice to haves?\nSpecific projects they can expect to work on?\nCandidate Details\nTarget candidate profile?\nAnti-patterns to watch out for?\nPossible career paths?\nPosition details\nBackfill or new position?\nLocation:\nHours:\nPay:\nWhen is this position targeted to come onboard:\nTeam details\nWho do they report to?\nHow big is the current team? Management/supervisory duties?\nWho else will this person interact with regularly?\nLooking back on a successful hire, what will this new hire have done to be considered as such in the first‚Ä¶\n30 days?\n90 days?\nYear?\nInterview process\nWhat will the typical interview process look like for this position?\nWho is part of the interview team?\nWhat will each of them be looking at?\nHow to sell the role\nWhy would someone choose this position over another option?\nAnything else that will be important for (Recruiter or RC) to know as they review and screen candidates? ‚Ä¶","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641838792,"objectID":"3feed7494fd3c5b7f4eee01e7b11b4bc","permalink":"https://iopsychist.netlify.app/post/opening-a-new-position/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/post/opening-a-new-position/","section":"post","summary":"When a new position is opened, the hiring manager should be able to express the why, the what, the when, and the where behind the position. This includes the reason the position is being requested, what the position will be responsible for and what projects the incumbent will likely be part of, when the position will be needed and the hours per week the position will require, and where the position will need to be located, among other relevant details to the position.","tags":["TA","Recruiting","Process","Guides"],"title":"Opening a New Position","type":"post"},{"authors":[],"categories":["Resources"],"content":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into databases. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.\n   Topic Link     Relational DB Design https://www3.ntu.edu.sg/home/ehchua/programming/sql/Relational_Database_Design.html   Building RDB from CSV files https://towardsdatascience.com/how-to-build-a-relational-database-from-csv-files-using-python-and-heroku-20ea89a55c63   10 DB Desgin best practices https://medium.com/quick-code/10-best-database-design-practices-1f10f3441730   using jupyter and SQL https://www.datacamp.com/community/tutorials/beginners-introduction-postgresql   Using PostgreSQL through SQLalchemy https://www.compose.com/articles/using-postgresql-through-sqlalchemy/   Using Databases with Python: Postgres, SQLAlchemy, and Alembic https://www.learndatasci.com/tutorials/using-databases-python-postgres-sqlalchemy-and-alembic/   ebook on sql querying https://use-the-index-luke.com/   ERD database modeling tool https://erdplus.com/   Building a Data Warehouse in Python using PostgreSQL https://towardsdatascience.com/building-a-data-warehouse-in-python-using-postgresql-77a42e38bd19   Data Curation Network Primers https://github.com/DataCurationNetwork/data-primers            Originally posted: January 10, 2022\n","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641855467,"objectID":"4fe309556d3d2150e4c083af2045a6ae","permalink":"https://iopsychist.netlify.app/post/resources-databases/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/post/resources-databases/","section":"post","summary":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into databases. Most of the resources listed here range from the beginner to intermediate level.","tags":["Database","Data Warehouse"],"title":"Resources: Databases","type":"post"},{"authors":[],"categories":["Resources","People Analytics"],"content":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into People Analytics. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.\n   Topic Link Note     r/IO Programming Starter Kit https://docs.google.com/document/u/0/d/1OZih--8wujuAdyxln5uvrRHOZQBvjI4pN6VHjPY5d_0/mobilebasic    Compensation Analytics Dashboard in Tableau https://public.tableau.com/profile/luisbatista#!/vizhome/HRAnalyticsDashboard_16097240839050/Compensation    Analyzing National Salary Equity in R with Tidyverse https://www.airweb.org/article/2019/04/17/analyzing-national-salary-equity-in-r-with-tidyverse    Glassdoor Report Analyzing Gender Pay Gap https://www.glassdoor.com/research/app/uploads/sites/2/2019/03/GD_Report_AnalyzingGenderPayGap_v2-2.pdf    Empath https://github.com/Ejhfast/empath-client From the author: Empath is a Python library for analyzing text data, something I‚Äôve been working a lot with lately. It‚Äôs a tool that can generate and validate new lexical categories on demand through deep learning and a corpus of more than 1.8 billion words. What‚Äôs cool about it is that it was built to be a reverse-engineered version of the Linguistic Inquiry and Word Count [LIWC], which has been used for psychometric applications and research. You can read more about LIWC here, and the Empath whitepaper can also be found here.   Data Skills for Reproducible Research https://psyteachr.github.io/reprores-v2/    Github of a Dr in IO Psych - lots of R resources https://github.com/jeromyanglim/r-vandenberghe-exercise \u0026lt;- this link is EFA specific example but click around and find out   EFA and CFA tutorials https://stats.idre.ucla.edu/spss/seminars/introduction-to-factor-analysis/a-practical-introduction-to-factor-analysis/    Psychometric open dataset https://openpsychometrics.org/_rawdata/    Investing in People Online https://orgtools.shinyapps.io/IIP3/ \u0026lt;‚Äì calculator for employee separations (turnover) absenteeism health and welfare attitudes and engagement workplace flexibility programs staffing utility payoffs from improved selection payoffs from training and development   How to Analyze the Gender Pay Gap https://www.glassdoor.com/research/app/uploads/sites/2/2019/03/GD_Report_AnalyzingGenderPayGap_v2-2.pdf    Grabbing and Analyzing Pay Data with Python https://towardsdatascience.com/a-beginners-guide-to-grabbing-and-analyzing-salary-data-in-python-e8c60eab186e    Re:Work (ie Google) guide to pay equity analysis https://rework.withgoogle.com/guides/pay-equity/steps/analyze-the-data-and-look-for-variance/    Network Analysis for Business Performance webinar series - focuses on overview as well as UCINET software https://connectedcommons.com/network-analysis-for-business-performance/    Handbook of Regression Modeling in People Analytics https://peopleanalytics-regression-book.org/     Originally posted: January 10, 2022\n","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641855038,"objectID":"0ba81cec8f167d011856f7ad5b343017","permalink":"https://iopsychist.netlify.app/post/resources-people-analytics/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/post/resources-people-analytics/","section":"post","summary":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into People Analytics. Most of the resources listed here range from the beginner to intermediate level.","tags":["Python","R"],"title":"Resources: People Analytics","type":"post"},{"authors":[],"categories":["Resources"],"content":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into Python and programming. By and large, the order in which they are presented reflects when I came into contact with them. All of them helped my understanding in some way. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.\n   Topic Link     Python101 by Mike Driscoll‚Äìvery helpful when just starting out. Occasionallly there are promos for free access https://leanpub.com/py101   python/dash http://coolsciencey.com/covid-dash-sciencey/   JPEG Image Scanning https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/   Debugging https://martinheinz.dev/blog/24   Beginner to Intermediate https://learnbyexample.github.io/curated-resources/python-intermediate/   Collection Of Data Science Resources https://www.theclickreader.com/   docker container https://www.pybootcamp.com/blog/how-to-containerize-python-application/   Robinhood API tutorial https://youtu.be/C5buU4zjjx0   nbdev https://www.fast.ai/2019/12/02/nbdev/   Fast AI course on PyTorch/Deep Learning https://course.fast.ai/   building an android app with Python https://towardsdatascience.com/building-android-apps-with-python-part-1-603820bebde8   Web scraping https://medium.com/python-in-plain-english/web-scraping-made-easy-with-python-and-chrome-windows-da85a08d54f3   Flask - Postgres - Heroku Tutorial https://blog.arctype.com/postgres-heroku/?utm_campaign=postgres-heroku\u0026amp;utm_medium=blog\u0026amp;utm_source=reddit   Exploratory Data Analysis with Python https://www.theclickreader.com/exploratory-data-analysis-with-python/   REST API with Django https://youtu.be/3DjZzK6IFa0   intermediate python resources https://learnbyexample.github.io/py_resources/intermediate.html   premade plots with python https://www.python-graph-gallery.com/   Turning python script into ‚ÄòReal‚Äô program with system services on linux https://medium.com/star-gazers/turning-your-python-script-into-a-real-program-cb702e16ed02   Data Visualization in python https://youtu.be/DevfjHOhuFc   Jupiter Notebook viewer with various tutorials https://nbviewer.jupyter.org/github/lightning-viz/lightning-example-notebooks/blob/master/index.ipynb   4 hour Python course https://youtu.be/rfscVS0vtbw   Data viz py package comparison https://share.streamlit.io/discdiver/data-viz-streamlit/main/app.py   Layout Parser https://github.com/Layout-Parser/layout-parser   3-Way Data Migration between Support Systems https://tilsupport.wordpress.com/2021/04/10/3-way-data-migration-between-support-systems/   Python Cheatsheet https://github.com/gto76/python-cheatsheet   Markdown language overview for Jupyter Notebook https://www.datacamp.com/community/tutorials/markdown-in-jupyter-notebook   Jupyter Notebook Extensions https://github.com/ipython-contrib/jupyter_contrib_nbextensions   Encoding Categorical Variables in Python https://pbpython.com/categorical-encoding.html   Progress Bar for iterables python package https://tqdm.github.io/   Pinguion Stats package (comparable to scipy and statsmodel) https://pingouin-stats.org/   Write an SQL query builder in 150 lines of Python! https://death.andgravity.com/query-builder-how   Data Science Course https://github.com/cmparlettpelleriti/CPSC392ParlettPelleriti   open-source, community-driven project to help data scientists improve fairness of AI systems https://fairlearn.org/   Bayesian Modeling and Computation in Python https://bayesiancomputationbook.com/welcome.html        Originally posted: January 10, 2022\n","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641854024,"objectID":"0fd46e9752a743e41b3bdf006acc6c09","permalink":"https://iopsychist.netlify.app/post/resources-python/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/post/resources-python/","section":"post","summary":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into Python and programming. By and large, the order in which they are presented reflects when I came into contact with them.","tags":["Python"],"title":"Resources: Python","type":"post"},{"authors":[],"categories":["Resources"],"content":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into R and Stats. By and large, the order in which they are presented reflects when I came into contact with them. All of them helped my understanding in some way. Most of the resources listed here range from the beginner to intermediate level. Hopefully they can be of help as you progress along your own journey.\n   Topic Link                             Repository of open access intro textbooks openintro.org                           Graduate Level: Intro to Probability and Statistics https://significantstatistics.com/index.php/Graduate_Level:_Intro_to_Probability_and_Statistics                           A visual introduction to probability and statistics https://seeing-theory.brown.edu/                           RShiny https://github.com/jennybc/googlesheets/tree/master/inst/shiny-examples                           Beginners guide to RShiny https://towardsdatascience.com/beginners-guide-to-creating-an-r-shiny-app-1664387d95b3                           underrated r packages https://medium.com/@alearrigo/the-most-underrated-r-packages-254e4a6516a1                           Modeling the 2020 elections scraping online polls in R https://medium.com/swlh/build-a-trump-vs-biden-prediction-model-with-r-from-scratch-fa66aee9f5c2                           Pandas gui https://github.com/adamerose/pandasgui                           using Socrata / Open Data https://hwangnyc.medium.com/using-r-to-access-311-service-request-from-nyc-open-data-using-socrata-open-data-api-and-the-83de00327a8c                           MIT Intro to Probability and Stats https://ocw.aprende.org/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/Syllabus/                           R for Data Science https://r4ds.had.co.nz/                           Graphics Cookbook https://r-graphics.org/                           Building Web Applications with Shiny https://rstudio-education.github.io/shiny-course/                           R/Stats/Python tutorial videos https://statisticsglobe.com/                           Visualizing Models and Communicating Results https://uvastatlab.github.io/phdplus/modelviz.html                           data viz what color to use https://blog.datawrapper.de/which-color-scale-to-use-in-data-vis/                           R data scraping pt 1 https://www.analyticssteps.com/blogs/data-scraping-r-programming-part-1                           Intro to Bayesian Inference https://m.youtube.com/watch?v=o90ogqUv4AA\u0026amp;feature=youtu.be                           text mining https://www.tidytextmining.com/                           dataset of us cities with lat long https://github.com/MarkMichon1/US-Cities-and-Data-COMPLETE-csv                           PsycModel - R package designed for psychologists https://jasonmoy28.github.io/psycModel/articles/quick-introduction.html                           Statistics of DOOM https://www.youtube.com/watch?v=zs2qY_iRlF0                           Overview of Bootstrapping https://statisticsbyjim.com/hypothesis-testing/bootstrapping/                           Causal Inference Textbook https://theeffectbook.net/                           Kernel Density Estimation https://mathisonian.github.io/kde/                           Reproducibility and the Groundhog package https://datacolada.org/95                           Statcheck R package for checking APA format papers https://mbnuijten.com/statcheck/                           Psychometrics R package http://psychonetrics.org/r-package/                           R Graph Gallery https://www.r-graph-gallery.com/                           EFA and CFA https://easystats.github.io/parameters/articles/efa_cfa.html                           Regular Expressions helper add in https://www.garrickadenbuie.com/project/regexplain/                           Psychometrics in R http://psychosystems.org/NetworkSchool                           Fair Models - A flexible tool for bias detection, visualization, and mitigation in AI algorhithms https://fairmodels.drwhy.ai/                           modern dive stats textbook. NHT concepts through simulation https://moderndive.com/9-hypothesis-testing.html                           Baseball analytics in R https://tht.fangraphs.com/a-short-ish-introduction-to-using-r-for-baseball-research/                           Data Science for Social Sciences http://datascience.tntlab.org/                           TNT lab website resources for IO and R https://rlanders.net/                           A tutorial on Bayesian Networks for psychopathology researchers https://psyarxiv.com/h4vxa/                           Fundamentals of Data Visualization https://clauswilke.com/dataviz/aesthetic-mapping.html                           portfoliodown package for making portfolio website ‚Ä¶","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641850723,"objectID":"87fdbaf7efd160e9ec3facaf4ee5f55d","permalink":"https://iopsychist.netlify.app/post/resources-r-stats/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/post/resources-r-stats/","section":"post","summary":"I‚Äôve gathered a number of resources which have helped me at various stages in my journey into R and Stats. By and large, the order in which they are presented reflects when I came into contact with them.","tags":["R","statistics"],"title":"Resources: R/Stats","type":"post"},{"authors":[],"categories":["Talent Acquisition"],"content":"A good recruiter will find strong candidates. At scale, however, an organization cannot simply rely on good recruiters to fill its open positions in a reliable, time bound manner. Moreover, doing so would make it difficult to consistently plan around hiring times. With the start of 2022 seeing more job postings for Recruiters than Software Engineers, your organization must be strategic in its approach to hiring. Furthermore, a strong TA process will increase the effectiveness of anyone on your team seeking to support recruiting.\nTo make Talent Acquisition a part of your organization‚Äôs strategic advantage, an effective Talent Acquisition process must be implemented. If you are facing resistance in your organization to adopting such a strategy, I lay out the business case for taking a strategic, data-driven approach.\nBusiness Case:\nLike any human process, the recruitment process for any company is‚Äìat its core‚Äìuncertain. The hiring team attempts to use incomplete information on the candidate‚Äôs past experience, current knowledge, dispositional traits, and future potential. The sources of this information may have varying degrees of accuracy and reliability. The candidate may exhibit different levels of performance during the interview process for reasons outside the awareness of the hiring team ‚Äì whether due to stress at the current job, activity in their personal life, even for such reasons of poor sleep or a bad commute. These inconsistencies in performance are, to a larger degree than most would like to admit, unrepresentative of on-the-job-performance. Each of the guesses, estimates, and inferences that the hiring team makes during the recruiting process open the door to uncertainty, bias, and error. Not to mention, the candidate is forming judgements based on impressions from the interviewers. Even if recruitment has gone well for a position whereby the team has accurately defined their needs, sourced quality candidates, and effectively narrowed in on the strongest candidate, the candidate may not choose to ultimately join the company.\nThe goal of a strong recruitment process is to minimize the noise associated with the selection process and to maximize the likelihood that the selected candidate chooses to join the company. In the face of such uncertainty, the process itself should not add to noise in the overall system. Rather, it should open a window to the signals that will allow the astute observer to understand the activity within their practices.\nIn an organization with multiple open positions and multiple team members supporting recruiting, this means standardization of practices. The actions of one recruiter should align with the actions of another. The milestones for one job should not differ substantially from the milestones of another. Failing to do this is costly. What happens when one recruiter gets sick, takes vacation, or leaves the organization? How does their coworker jump in and know what‚Äôs going on? If there is no understanding of metrics, how does the organization know where to put its resources? If there is no sense for time to hire, how does the team know whether they are outperforming the market or not? If new hires are not succeeding in the position, how does the company know where the function is broken in order to make changes?\nAdopting a framework that enables consistent processes allows for good data to be captured on all parts of the process, thus opening a window to answer these questions. You may be collecting such data already, but without this standardization what does time to hire mean, in aggregate, across your organization? Is it one day because you only add candidates into the system once they‚Äôve completed all interviews and you want to make an offer? Is it 120 days because you sometimes don‚Äôt bother marking them as hired since you‚Äôd rather get started with their onboarding than make a quick clerical adjustment to the system? What if your ATS tells you that 65% of your hires come from LinkedIn Job Postings, your most expensive vendor, when really you haven‚Äôt captured source details for 50% of your top performing hires? Do you invest more in LinkedIn and hope to get top performers? Or do you go with you gut and invest in job fairs since you have a feeling that your best hires came through your college recruiting efforts? That‚Äôs a tough call, and it doesn‚Äôt need to be if you consistently practice good data hygiene.\nHow does this enable success? It allows your team members to collaborate, helping each other out on the those tough to fill roles. It allows new hires to quickly get up to speed with what, exactly, your process is. It allows junior members to provide a similar candidate experience as your tenured veterans. Essentially, a good process ‚Äòbakes in‚Äô best practices‚Äìreducing onboarding times and building institutional knowledge that transcends any one team member.\nOnce a solid TA process has been established, you can begin collecting data on what works for your ‚Ä¶","date":1641168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641771949,"objectID":"6f53b16a896ba4f382edf8d6c3b7c0ac","permalink":"https://iopsychist.netlify.app/post/talent-acquisition-process-framework/","publishdate":"2022-01-03T00:00:00Z","relpermalink":"/post/talent-acquisition-process-framework/","section":"post","summary":"A good recruiter will find strong candidates. At scale, however, an organization cannot simply rely on good recruiters to fill its open positions in a reliable, time bound manner. Moreover, doing so would make it difficult to consistently plan around hiring times.","tags":["TA"],"title":"Talent Acquisition Process Framework","type":"post"},{"authors":["IOPsychist"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://iopsychist.netlify.app/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  **Two**  Three   A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}   Custom CSS Example Let‚Äôs make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://iopsychist.netlify.app/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://iopsychist.netlify.app/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://iopsychist.netlify.app/project/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":["IOPsychist","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://iopsychist.netlify.app/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["IOPsychist","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://iopsychist.netlify.app/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://iopsychist.netlify.app/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]